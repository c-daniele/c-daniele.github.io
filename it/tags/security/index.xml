<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>security on Cdani&#39;s Blog</title>
    <link>https://c-daniele.github.io/it/tags/security/</link>
    <description>Recent content in security on Cdani&#39;s Blog</description>
    <image>
      <title>Cdani&#39;s Blog</title>
      <url>https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-IT</language>
    <lastBuildDate>Thu, 15 May 2025 00:00:00 +0200</lastBuildDate><atom:link href="https://c-daniele.github.io/it/tags/security/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Policy Puppetry Prompt Injection</title>
      <link>https://c-daniele.github.io/it/posts/2025-05-15-policy-puppetry/</link>
      <pubDate>Thu, 15 May 2025 00:00:00 +0200</pubDate>
      
      <guid>https://c-daniele.github.io/it/posts/2025-05-15-policy-puppetry/</guid>
      <description>Policy Puppetry Prompt Injection Qualche giorno fa ho fatto qualche esperimento con alcune tecniche di Jailbraking, che condivido nel repo. Sono partito da un articolo di HiddenLayer, di qualche settimana fa, in cui il team di ricerca ha pubblicato un articolo che descrive una tecnica piuttosto creativa e ingegnosa di jailbreaking, per bypassare i safety guardails e l&amp;rsquo;allineamento dei modelli di frontiera. La tecnica sembra essere universale ed applicabile con un singolo prompt a più modelli ed è in grado di mostrare contenuti tipicamente non safety o addirittura mostrare porzioni del system prompt nativo.</description>
    </item>
    
  </channel>
</rss>
