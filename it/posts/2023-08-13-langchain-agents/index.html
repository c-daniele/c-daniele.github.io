<!doctype html><html lang=en-IT><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Langchain pt. 2 - Analisi dati tramite Agenti - Cdani's Blog</title><meta name=Description content="Cdani's Blog"><meta property="og:url" content="https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/"><meta property="og:site_name" content="Cdani's Blog"><meta property="og:title" content="Langchain pt. 2 - Analisi dati tramite Agenti"><meta property="og:description" content="Intro Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d’uso con dati non strutturati in formato pdf.
Seguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:
è possibile, tramite l’AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?"><meta property="og:locale" content="en_IT"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-13T19:00:00+02:00"><meta property="article:modified_time" content="2023-08-13T19:00:00+02:00"><meta property="article:tag" content="GenAI"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Agents"><meta property="og:image" content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Langchain pt. 2 - Analisi dati tramite Agenti"><meta name=twitter:description content="Intro Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d’uso con dati non strutturati in formato pdf.
Seguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:
è possibile, tramite l’AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?"><meta name=application-name content="Cdani's Blog"><meta name=apple-mobile-web-app-title content="Cdani's Blog"><meta name=referrer content="no-referrer"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/logo_cd_v3.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#00872b><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/><link rel=prev href=https://c-daniele.github.io/it/posts/2023-07-24-langchain-helloworld-pdf/><link rel=next href=https://c-daniele.github.io/it/posts/2024-04-20-langchain-api/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Langchain pt. 2 - Analisi dati tramite Agenti","inLanguage":"en-IT","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/c-daniele.github.io\/it\/posts\/2023-08-13-langchain-agents\/"},"genre":"posts","keywords":"GenAI, Langchain, Agents","wordcount":2732,"url":"https:\/\/c-daniele.github.io\/it\/posts\/2023-08-13-langchain-agents\/","datePublished":"2023-08-13T19:00:00+02:00","dateModified":"2023-08-13T19:00:00+02:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Me"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script>const query=window.matchMedia("(prefers-color-scheme: dark)");function applyTheme(){let e=window.localStorage?.getItem("theme")||"auto",t=e==="dark"||e==="auto"&&query.matches;document.body.setAttribute("theme",t?"dark":"light"),document.body.setAttribute("cfg-theme",e)}applyTheme(),query.addEventListener("change",applyTheme)</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/it/ title="Cdani's Blog"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo_cd_v3.svg data-srcset="/logo_cd_v3.svg, /logo_cd_v3.svg 1.5x, /logo_cd_v3.svg 2x" data-sizes=auto alt=/logo_cd_v3.svg title=/logo_cd_v3.svg>Cdani's Blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/it/posts/>Archive </a><a class=menu-item href=/it/tags/>Tags </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=Search... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Cerca><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Chiaro><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Cambiare il tema"><i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="menu-item language" title="Scegliere la lingua"><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select id=language-select-desktop onchange="location=this.value"><option value=/it/posts/2023-08-13-langchain-agents/ selected>Italiano</option><option value=/en/posts/2023-08-13-langchain-agents/>English</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/it/ title="Cdani's Blog"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo_cd_v3.svg data-srcset="/logo_cd_v3.svg, /logo_cd_v3.svg 1.5x, /logo_cd_v3.svg 2x" data-sizes=auto alt=/logo_cd_v3.svg title=/logo_cd_v3.svg>Cdani's Blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=Search... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Cerca><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Chiaro><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Annulla</a></div><a class=menu-item href=/it/posts/ title>Archive</a><a class=menu-item href=/it/tags/ title>Tags</a><a href=javascript:void(0); class="menu-item theme-switch" title="Cambiare il tema">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class=menu-item title="Scegliere la lingua"><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select onchange="location=this.value"><option value=/it/posts/2023-08-13-langchain-agents/ selected>Italiano</option><option value=/en/posts/2023-08-13-langchain-agents/>English</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contenuti</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Langchain pt. 2 - Analisi dati tramite Agenti</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/it/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Me</a></span>&nbsp;<span class=post-category>incluso in <a href=/it/categories/software-development/><i class="far fa-folder fa-fw" aria-hidden=true></i>Software Development</a>&nbsp;<a href=/it/categories/artificial-intelligence/><i class="far fa-folder fa-fw" aria-hidden=true></i>Artificial Intelligence</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime="August 13, 2023">August 13, 2023</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;2732 parole&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;13 minuti&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contenuti</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#agenti>Agenti</a></li><li><a href=#e-qui-che-entrano-in-gioco-gli-agent>E&rsquo; qui che entrano in gioco gli &ldquo;Agent&rdquo;.</a></li><li><a href=#la-descrizione-dello-scenario>La descrizione dello scenario</a><ul><li><a href=#il-dataset>Il dataset</a></li><li><a href=#la-configurazione-software>La configurazione software</a></li></ul></li><li><a href=#le-challenges>Le challenges</a><ul><li><a href=#caso-a---calcolo-di-un-semplice-kpi>Caso A - Calcolo di un semplice KPI</a></li><li><a href=#caso-b---informazioni-aggiuntive>Caso B - informazioni aggiuntive</a></li><li><a href=#caso-c---esecuzione-combinata-sqlricerca>Caso C - esecuzione combinata SQL+Ricerca</a></li></ul></li><li><a href=#conclusioni>Conclusioni</a></li></ul></nav></div></div><div class=content id=content><h2 id=intro>Intro</h2><p>Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d&rsquo;uso con dati non strutturati in formato pdf.</p><p>Seguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:</p><blockquote><p>è possibile, tramite l&rsquo;AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?</p></blockquote><h2 id=agenti>Agenti</h2><p>I LLM sono estremamente potenti, ma possono rivelarsi inefficaci nel rispondere a domande che richiedono una conoscenza di dettaglio non strettamente integrata nel training del modello. In rete esistono decine di esempi che riescono a cogliere in fallo ChatGPT tramite allucinazioni o mancata risposta (es: previsioni meteo, ultime notizie, gossip o anche operazioni matematiche particolari).</p><p>I framework come LangChain possono superare queste limitazioni tramite la definizione di componenti specifici e &ldquo;data-aware&rdquo;, ma solitamente le azioni eseguite dal framework sono predeterminate. In altre parole, <strong>il framework utilizza un Language Model per eseguire delle azioni, ma esse sono &ldquo;hardcoded&rdquo;</strong> e in moltissimi casi questo può rendere del tutto inefficaci i modelli di AI, perché non si riesce ad aggiungere quel livello di dinamismo tale da pilotare le specifiche azioni sulla base dell&rsquo;input utente.</p><h2 id=e-qui-che-entrano-in-gioco-gli-agent>E&rsquo; qui che entrano in gioco gli &ldquo;Agent&rdquo;.</h2><p>Gli Agent sono dei componenti che hanno a disposizione una serie di Tool per svolgere delle azioni specifiche, come ad esempio fare una ricerca su Wikipedia o su Google, o eseguire codice Python o addirittura accedere al file system locale.</p><p>Gli Agent utilizzano un LLM per interpretare l&rsquo;input dell&rsquo;utente e decidere di volta come procedere, cioè:</p><ol><li>Quale tool utilizzare tra gli N a disposizione</li><li>Cosa passare come input al tool</li><li>Decidere se si è riusciti ad ottenere una risposta al quesito iniziale oppure ripetere gli step 1 e 2</li></ol><p>Questo approccio prende ispirazione da un framework denominato ReAct che è stato definito a fine 2022 da un team congiunto di ricercatori di Google e della Princeton University, che trovate <a href=https://arxiv.org/abs/2210.03629 target=_blank rel="noopener noreffer">descritto qui</a>. In LangChain, ne esistono diverse implementazioni, ma la più comune prende il nome di &ldquo;<em>Zero-shot ReAct</em>&rdquo; e può essere schematizzata secondo il workflow in Figura 1.</p><figure><img src=/images/20230813/Agent_Diagram_v2.png><figcaption><h4>Figura 1 - Workflow semplificato per gli agenti di tipo "Zero-shot ReAct"</h4></figcaption></figure><p>Un aspetto particolarmente rilevante da tenere in considerazione è relativo al fatto che gli agenti di questo tipo non hanno memoria e discriminano le loro azioni <strong>unicamente sulla base del testo in input e della descrizione del tool</strong>. E&rsquo; dunque importante che i tool includano anche una descrizione efficace ai fini di una corretta interpretazione da parte del LLM.</p><p>Per semplicità, i tool di LangChain sono talvolta raggruppati in gruppi denominati &ldquo;Toolkits&rdquo;. Nella documentazione ufficiale troverete un toolkit predefinito che si chiama &ldquo;SQLDatabaseToolkit&rdquo;, per configurare appunto un agente SQL.</p><h2 id=la-descrizione-dello-scenario>La descrizione dello scenario</h2><p>Come preannunciato all&rsquo;inizio dell&rsquo;articolo, vogliamo fare una vera e propria analisi in maniera automatica sui dati presenti in un DB relazionale, supponendo di non avere alcuna conoscenza del modello dati né tantomeno competenze SQL. Il punto di partenza sarà infatti un prompt testuale in lingua naturale.</p><p>Da un punto di vista tecnico, l&rsquo;esercizio è facilissimo perché, oltre al toolkit, LangChain mette a disposizione un metodo di utility per la definizione di un SqlAgent in cui dobbiamo passare solo alcuni parametri come i puntamenti al DB, il tipo di LLM, etc..</p><p>A prima vista, <a href=https://python.langchain.com/docs/integrations/toolkits/sql_database target=_blank rel="noopener noreffer">gli esempi riportati nella documentazione ufficiale</a> sembrano già molto interessanti. Oltre ai casi banali (es: DESCRIBE di una tabella), viene infatti mostrato come l&rsquo;agente sia in grado di fare inferenza sui metadati per capire come aggregare i dati o mettere in JOIN 2 o più tabelle. Tutto ciò in totale autonomia.</p><p>Per non ripetere lo stesso identico esempio presente nella documentazione ed introdurre qualche complicazione in più, decido di creare una versione potenziata del toolkit standard, che sia in grado di fare anche ricerche su Google.</p><h3 id=il-dataset>Il dataset</h3><p>La documentazione ufficiale include degli esempi che fanno uso di un DB di prova basato su SqlLite e denominato &ldquo;Chinook&rdquo;, che simula un media store e che trovate anche nel sito ufficiale di SqlLite.</p><p>Dando un occhio al modello dati e ai dati stessi, ho guardato con sospetto gli entusiasmanti risultati che hanno riportato, perché il DB è a mio avviso non è rappresentativo di un caso reale:</p><ul><li>i nomi delle tabelle e delle colonne sono tutti abbastanza parlanti ed in lingua inglese, inoltre non viene fatto uso di una naming convention</li><li>il DB sembra praticamente in terza forma normale: improbabile laddove si voglia fare pura analisi dati</li><li>file .db SqlLite in locale? Si tratta di un caso molto lontano dalla realtà!</li></ul><p>Fortunatamente ho a disposizione un DB Athena su un mio account AWS con alcune strutture dati più vicine ad un caso reale e di cui conosco un po&rsquo; la semantica del dato. Si tratta di OpenData del Comune di Milano, relativi ai <strong>transiti all&rsquo;interno dei varchi di AreaC</strong>. In realtà Athena non è un vero DB, quanto piuttosto un SQL-Engine basato su Presto, ma con le opportune configurazioni, AWS mette a disposizione un endpoint che permette di accedervi come se fosse un vero DBMS.</p><p>Il Data Model è semplicissimo: si tratta di 2 tabelle dei fatti, che fanno riferimento al conteggio degli ingressi (dettaglio+aggregato), legate entrambe ad una tabella di decodifica dei varchi, in cui sono indicati alcuni attributi tra cui la posizione geografica esatta del varco. In tutti e 3 i casi, si tratta di tabelle Iceberg memorizzate su S3 e mappate su Athena tramite il catalogo di Glue.</p><p>I dataset originari li trovate sul <a href=https://dati.comune.milano.it/group/tran target=_blank rel="noopener noreffer">portale OpenData ufficiale</a>. Si tratta di circa 4 anni di dati (circa 101 milioni di record nella tabella di cardinalità massima).</p><p>Di seguito le DDL delle tabelle con qualche commento che ho aggiunto qui per semplicità (e che dunque l&rsquo;agente non aveva a disposizione&mldr;).</p><figure><img src=/images/20230813/screenshot1.png><figcaption><h4>Figura 2 - DDL tabella di dettaglio</h4></figcaption></figure><figure><img src=/images/20230813/screenshot2.png><figcaption><h4>Figura 3 - DDL tabella aggregata</h4></figcaption></figure><figure><img src=/images/20230813/screenshot3.png><figcaption><h4>Figura 2 - DDL tabella di decodifica dei varchi</h4></figcaption></figure><p>Nella tabella aggregata, oltre a rimuovere qualche attributo, ho fatto una sorta di pivot sul tipo di alimentazione, calcolando i diversi transiti in COLONNA anziché in RIGA, riducendo la cardinalità di circa il 92%. A parte questo, le 2 tabelle dei fatti sono praticamente identiche.</p><p>La tabella di decodifica dei varchi, oltre al nome descrittivo, contiene anche le coordinate geografiche.</p><p>Come si può vedere, ho usato una naming convention, ma essa è <strong>volutamente imperfetta</strong>, ad esempio è un mix di inglese ed italiano.</p><h3 id=la-configurazione-software>La configurazione software</h3><p>Riporto di seguito gli import e le configurazioni di base del codice python:</p><div class="code-block open" style="counter-reset:code-block 0"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copia negli appunti"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents</span> <span class=kn>import</span> <span class=n>create_sql_agent</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.sql_database</span> <span class=kn>import</span> <span class=n>SQLDatabase</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.llms.openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents.agent_types</span> <span class=kn>import</span> <span class=n>AgentType</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>urllib.parse</span> <span class=kn>import</span> <span class=n>quote_plus</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ExtendedSqlDatabaseToolkit</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># carico le variabili di ambiente</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># connection string</span>
</span></span><span class=line><span class=cl><span class=n>conn_str</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;awsathena+rest://</span><span class=si>{aws_access_key_id}</span><span class=s2>:</span><span class=si>{aws_secret_access_key}</span><span class=s2>@&#34;</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;athena.</span><span class=si>{region_name}</span><span class=s2>.amazonaws.com:443/&#34;</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;</span><span class=si>{schema_name}</span><span class=s2>?s3_staging_dir=</span><span class=si>{s3_staging_dir}</span><span class=s2>&amp;work_group=</span><span class=si>{wg}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># inizializzazione del DB</span>
</span></span><span class=line><span class=cl><span class=n>db</span> <span class=o>=</span> <span class=n>SQLDatabase</span><span class=o>.</span><span class=n>from_uri</span><span class=p>(</span><span class=n>conn_str</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>aws_access_key_id</span><span class=o>=</span><span class=n>quote_plus</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_AK&#39;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>aws_secret_access_key</span><span class=o>=</span><span class=n>quote_plus</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_SAK&#39;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>region_name</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_REGION&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>schema_name</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_ATHENA_SCHEMA&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>s3_staging_dir</span><span class=o>=</span><span class=n>quote_plus</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_S3_OUT&#39;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>wg</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_ATHENA_WG&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl> <span class=p>,</span> <span class=n>include_tables</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;xtdpl1_ingressi_detailed&#39;</span><span class=p>,</span> <span class=s1>&#39;xtdpl1_ingressi_aggregated&#39;</span><span class=p>,</span> <span class=s1>&#39;xtdpl1_varchi&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl> <span class=p>,</span> <span class=n>sample_rows_in_table_info</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># definizione del toolkit tramite classe Custom</span>
</span></span><span class=line><span class=cl><span class=n>toolkit</span> <span class=o>=</span> <span class=n>ExtendedSqlDatabaseToolkit</span><span class=p>(</span><span class=n>db</span><span class=o>=</span><span class=n>db</span><span class=p>,</span> <span class=n>llm</span><span class=o>=</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># inizializzazione dell&#39;Agent</span>
</span></span><span class=line><span class=cl><span class=n>agent_executor</span> <span class=o>=</span> <span class=n>create_sql_agent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>llm</span><span class=o>=</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>toolkit</span><span class=o>=</span><span class=n>toolkit</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>agent_type</span><span class=o>=</span><span class=n>AgentType</span><span class=o>.</span><span class=n>ZERO_SHOT_REACT_DESCRIPTION</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div></div><p>LangChain utilizza SQLAlchemy quindi garantisce già l&rsquo;accesso a un gran numero di DBMS senza la necessità di inventarsi nulla.</p><p>Da notare che oltre alle variabili di ambiente relative ad AWS ed esplicitamente referenziate sopra, occorre anche settare le variabili:</p><ul><li>OPENAI_API_KEY: associata all&rsquo;account OpenAI, essenziale per l&rsquo;utilizzo del LLM</li><li>SERPAPI_API_KEY: associata all&rsquo;account SerpApi, al fine di fare programmaticamente ricerche su Google. Esiste una versione FREE che supporta un numero di chiamate mensili &lt; 100</li></ul><p>Le opzioni indicate in riga 29 e 30 servono per limitare il raggio d&rsquo;azione dell&rsquo;agente ed evitare che faccia ragionamenti troppo estesi su tutto il catalogo o su un sample di dati troppo ampio. Il rischio è infatti quello di saturare molto facilmente i token disponibili dal LLM.</p><p>Il toolkit istanziato in riga 34 è una mia classe custom, che estende il SQLToolkit standard messo a disposizione da LangChain. Trattandosi di poche righe di codice, aggiungo anche questo:</p><div class="code-block open" style="counter-reset:code-block 0"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copia negli appunti"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;Enhanced Toolkit for interacting with SQL databases and search over the internet&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>List</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents.agent_toolkits</span> <span class=kn>import</span> <span class=n>SQLDatabaseToolkit</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.tools</span> <span class=kn>import</span> <span class=n>BaseTool</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents</span> <span class=kn>import</span> <span class=n>load_tools</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ExtendedSqlDatabaseToolkit</span><span class=p>(</span><span class=n>SQLDatabaseToolkit</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Enhanced Toolkit for interacting with SQL databases and search over the internet&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_tools</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>BaseTool</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>sqlTools</span> <span class=o>=</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=n>get_tools</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>additionalTools</span> <span class=o>=</span> <span class=n>load_tools</span><span class=p>([</span><span class=s2>&#34;serpapi&#34;</span><span class=p>],</span> <span class=n>llm</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>llm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>additionalTools</span><span class=o>+</span><span class=n>sqlTools</span></span></span></code></pre></div></div><p>Oltre alle librerie esplicitamente referenziate, occorre anche installare le librerie &ldquo;openai&rdquo; e &ldquo;pyathena&rdquo;.</p><h2 id=le-challenges>Le challenges</h2><p>Ho sottoposto all&rsquo;agente diverse domande, cercando di stressare le diverse componenti (es: capacità di individuare la semantica del dato, capire cosa cercare su google, quando/se andare nella tabella di dettaglio, etc etc).</p><p>Mi limiterò nel seguito a descrivere un paio di esempi, ma prima faccio qualche considerazione generale.</p><p>Il modello standard utilizzato dalle librerie OpenAI è <em>Text-davinci-003</em>. Questo modello, è molto più ampio e più costoso (circa 10 volte di più!) di quello usato da ChatGPT (<em>GPT-3.5-Turbo</em>). Esiste molta letteratura che descrive l&rsquo;efficacia di entrambi e di come il secondo, pur essendo sulla carta più piccolo (6 vs 175 miliardi di parametri), possa comunque avere risultati uguali o in alcuni casi addirittura migliori.</p><p>Personalmente ho usato quasi esclusivamente il primo dei 2 e le poche prove che ho fatto con GPT-3.5-Turbo hanno avuto risultati nettamente peggiori, ma non ho approfondito molto questo aspetto, a cui magari dedicherò un altro articolo.</p><h3 id=caso-a---calcolo-di-un-semplice-kpi>Caso A - Calcolo di un semplice KPI</h3><blockquote><p><em>trova le coordinate e il nome descrittivo del varco in cui ci sono più transiti di veicoli diesel nel periodo di Agosto 2020. Considera gli ingressi effettivamente areac ed escludi i mezzi di servizio</em></p></blockquote><p>L&rsquo;output restituito è indicato in Figura 3 e se date un occhio alle righe che iniziano per &ldquo;Action&rdquo;, &ldquo;Observation&rdquo; e &ldquo;Thought&rdquo;, vedrete che esso rispetta quanto previsto nel modello &ldquo;Zero-shot ReAct&rdquo;.</p><figure><img src=/images/20230813/screenshot6_result_1.png><figcaption><h4>Figura 3 - Output caso A</h4></figcaption></figure><p>In particolare, l&rsquo;agente parte con l&rsquo;identificazione della <strong>Action</strong> (sql_db_list_tables) e dell&rsquo;input (nessun in input in questo caso), ottenendo (<strong>Observation</strong>) le 3 tabelle su cui abbiamo programmaticamente ristretto la sua visibilità. In teoria il tool potrebbe esplorare tutto il catalogo ma, come anticipato sopra, ho voluto restringere il campo per evitare di saturare i token messi a disposizione del modello.</p><p>A questo punto l&rsquo;agente passa il controllo al LLM (<strong>Thought</strong>) per decidere la prossima azione e tramite esso determina che le uniche 2 tabelle di interesse sono la tabella dei fatti aggregata e la tabella di decodifica dei varchi.</p><p>E&rsquo; interessante che già in questa fase abbia dedotto che sia meglio fare la query sulla tabella aggregata rispetto a quella di dettaglio, ma mi stranisce un po&rsquo; il fatto che abbia fatto questa deduzione <strong>basandosi unicamente sulla naming della tabella</strong>, poiché l&rsquo;inferenza sui metadati e sui dati viene fatta solo in un momento successivo. In tal senso, il risultato finale potrebbe non essere quello corretto qualora le 2 tabelle avessero avuto un perimetro dati diverso (ad esempio qualora la tabella aggregata contenesse solo l&rsquo;ultimo anno).</p><p>Dopo aver letto i metadati e fatto un carotaggio dei dati, il LLM costruisce la query. In questo caso specifico si vede chiaramente che il modello indovina la sintassi della query al primo tentativo, ma ho sperimentato diversi casi in cui esso va a tentativi, correggendo di volta in volta la sintassi fino ad arrivare alla query definitiva (vedi casi B e C).</p><p>Il resto è autodescritto nell&rsquo;immagine.</p><p>Un paio di commenti:</p><ul><li>il modello è riuscito a implementare perfettamente i filtri che avevo in mente nel prompt, tramite inferenza sulla naming e/o sui dati</li><li>ho fatto altri tentativi rimuovendo la tabella aggregata e lasciando solo quella di dettaglio e ho ottenuto lo stesso risultato. Da notare però che la tabella di dettaglio ha il KPI in riga anziché in colonna, dunque in quel caso il modello ha capito che andava applicato il filtro &ldquo;des_tipo_alimentazione = &lsquo;diesel&rsquo;&rdquo;</li><li>come da attese, non è stata fatta alcuna ricerca su google, perché ovviamente non serviva</li></ul><h3 id=caso-b---informazioni-aggiuntive>Caso B - informazioni aggiuntive</h3><blockquote><p><em>trova il varco in cui ci sono più transiti di veicoli diesel nel periodo di Agosto 2020, includendo solo ingressi areac ed escludendo i mezzi di servizio. Restituiscimi anche i 3 varchi più vicini ad esso</em></p></blockquote><p>Qui, il LLM mi ha sorpreso: ho aggiunto la frase finale per costringerlo a fare una ricerca su Google, ma non avevo pensato che partendo dalle coordinate geografiche fosse possibile calcolare la distanza con delle operazioni matematiche, dunque il tool (e cioè il modello LLM sottostante) ha eseguito l&rsquo;intero task all&rsquo;interno del DB tramite le funzioni <em>ST_POINT</em> ed <em>ST_DISTANCE</em> come mostrato in Figura 8.</p><p>Ho omesso la prima parte dell&rsquo;output perché identica al caso precedente.</p><figure><img src=/images/20230813/screenshot7_result_6.png><figcaption><h4>Figura 4 - Output caso B</h4></figcaption></figure><p>Come si vede dai vari messaggi di errore, in questo caso il modello ha avuto diverse &ldquo;allucinazioni&rdquo; nella costruzione della query SQL, ma è riuscito a correggerli fino ad arrivare alla query definitiva perché l&rsquo;agente ha restituito al modello LLM i feedback di tali errori tramite i loop <em>Action-Observation-Thought</em>.</p><h3 id=caso-c---esecuzione-combinata-sqlricerca>Caso C - esecuzione combinata SQL+Ricerca</h3><p>L&rsquo;estrema semplicità del modello dati non mi ha aiutato molto nel creare una richiesta sufficientemente articolata, dunque ho dovuto fare un po&rsquo; di prompt engineering per costringerlo a fare una ricerca sul web. Alla fine sono riuscito ad ottenere qualcosa con una richiesta di questo tipo:</p><blockquote><p><em>trova le coordinate e il nome descrittivo del varco in cui ci sono più transiti di veicoli diesel nel mese di Agosto 2020. Cerca la fermata dei mezzi pubblici più vicina a quel varco</em></p></blockquote><p>Qui sono accadute 2 cose strane:</p><ol><li>nonostante la prima parte del prompt fosse quasi identica al caso A (ho usato &ldquo;<em>nel mese di</em>&rdquo; anziché &ldquo;<em>nel periodo di</em>&rdquo;), il LLM esegue l&rsquo;operazione di MAX anziché di SUM</li><li>come da attese, l&rsquo;agente ha eseguito la ricerca tramite SerpApi per individuare la fermata dei mezzi ma, anziché usare le coordinate, ha usato il nome descrittivo del varco. Il risultato chiaramente non è in linea con le aspettative, perché viene restituita una fermata dei mezzi della città di Venezia</li></ol><figure><img src=/images/20230813/screenshot8_result_7.png><figcaption><h4>Figura 4 - Output caso C</h4></figcaption></figure><h2 id=conclusioni>Conclusioni</h2><p>Come già ho scritto nel precedente articolo, la curva di apprendimento per adottare LangChain è piuttosto bassa. Bastano poche righe di codice per ottenere un effetto &ldquo;wow&rdquo; e consentire a chiunque di implementare una propria soluzione custom, magari integrata con il resto dell&rsquo;ecosistema aziendale (repository documentali, Data APIs, mail server, shared file systems, &mldr;) e/o con il proprio LLM (ad esempio, è possibile integrare una propria installazione di Llama 2 on-premise) laddove non si vogliano condividere dati al di fuori dell&rsquo;organizzazione aziendale.</p><p>D&rsquo;altro canto, gli esempi che ho riportato sopra sono da considerarsi come tutorial semplificati per prendere dimestichezza con il framework.</p><p>Per mettere a terra delle soluzioni reali, serve un approccio più strutturato, che sfrutti meglio le caratteristiche del framework e tenga conto delle peculiarità dei modelli.</p><p>Ad esempio, mi sono reso conto che non è stata una scelta saggia quella di unire le funzionalità SQL e di ricerca SerpApi in un unico toolkit e che sarebbe stato meglio integrare le 2 funzionalità tramite agent/chain separati.</p><p>Come altro esempio, ho notato che nel pacchetto &ldquo;experimental&rdquo; è presente una classe che si chiama &ldquo;<em>SQLDatabaseChain</em>&rdquo; che con poche righe di codice permette di sviluppare un Tool Sql from scratch, bypassando completamente il toolkit standard:</p><div class="code-block open" style="counter-reset:code-block 0"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copia negli appunti"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sql_chain</span> <span class=o>=</span> <span class=n>SQLDatabaseChain</span><span class=o>.</span><span class=n>from_llm</span><span class=p>(</span><span class=n>llm</span><span class=o>=</span><span class=n>llm</span><span class=p>,</span> <span class=n>db</span><span class=o>=</span><span class=n>db</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sql_tool</span> <span class=o>=</span> <span class=n>Tool</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s1>&#39;Areac DB&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>func</span><span class=o>=</span><span class=n>sql_chain</span><span class=o>.</span><span class=n>run</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Database che contiene i dati relativi agli ingressi nei varchi dell&#39;area C di Milano.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; Le tabelle principali sono xtdpl1_ingressi_aggregated e xtdpl1_varchi.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; La tabella xtdpl1_ingressi_aggregated contiene le principali misure, come ad esempio il conteggio del numero di accessi per ciascuno dei varchi e per ciascun giorno dell&#39;anno.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; Il campo relativo alla dimensione tempo si chiama dat_year_month ed è di tipo numerico, nel classico formato YYYYMM.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; Il campo flg_areac è di tipo BOOLEAN (true/false) ed indica se si tratta di un ingresso effettivamente conteggiato come areac.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; La tabella xtdpl1_varchi contiene la decodifica dei varchi. La chiave principale di questa tabella è il campo &#39;id&#39;, che identifica il varco. Gli altri attributi sono descrittivi.&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div></div><p>Poiché l&rsquo;agente utilizza il LLM per decidere QUALE tool utilizzare e COME utilizzarlo <strong>unicamente in base alla descrizione del tool</strong>, questo approccio ha il grande vantaggio di migliorare le performance semplicemente aggiungendo una descrizione efficace del DB all&rsquo;interno del tool, <strong>senza modificare in alcun modo il modello LLM</strong>.
Nel mio caso, ad esempio, ho aggiunto incrementalmente un gran numero di dettagli e ho notato un progressivo miglioramento delle performance.</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Aggiornato il August 13, 2023</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Condividi su X" data-sharer=x data-url=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/ data-title="Langchain pt. 2 - Analisi dati tramite Agenti" data-hashtags=GenAI,Langchain,Agents><i class="fab fa-x-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Condividi su Threads" data-sharer=threads data-url=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/ data-title="Langchain pt. 2 - Analisi dati tramite Agenti"><i class="fab fa-threads fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Condividi su Facebook" data-sharer=facebook data-url=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/ data-hashtag=GenAI><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Condividi su Hacker News" data-sharer=hackernews data-url=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/ data-title="Langchain pt. 2 - Analisi dati tramite Agenti"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Condividi su Line" data-sharer=line data-url=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/ data-title="Langchain pt. 2 - Analisi dati tramite Agenti"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@15.14.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Condividi su 微博" data-sharer=weibo data-url=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/ data-title="Langchain pt. 2 - Analisi dati tramite Agenti"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Condividi su Diaspora" data-sharer=diaspora data-url=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/ data-title="Langchain pt. 2 - Analisi dati tramite Agenti" data-description><i class="fab fa-diaspora fa-fw" aria-hidden=true></i></a><a href="https://t.me/share/url?url=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f&amp;text=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti" target=_blank title="Condividi su Telegram"><i class="fab fa-telegram fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/it/tags/genai/>GenAI</a>,&nbsp;<a href=/it/tags/langchain/>Langchain</a>,&nbsp;<a href=/it/tags/agents/>Agents</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Indietro</a></span>&nbsp;|&nbsp;<span><a href=/it/>Home</a></span></section></div><div class=post-nav><a href=/it/posts/2023-07-24-langchain-helloworld-pdf/ class=prev rel=prev title="LLM - Esperimenti con LangChain - Parte 1"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>LLM - Esperimenti con LangChain - Parte 1</a>
<a href=/it/posts/2024-04-20-langchain-api/ class=next rel=next title="Langchain pt. 3 - Come invocare API Rest in linguaggio naturale">Langchain pt. 3 - Come invocare API Rest in linguaggio naturale<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Torna all'inizio"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i></a></div><div id=fixed-buttons-hidden><a href=# id=view-comments class=fixed-button title="Vedi commenti"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script src=/lib/lunr/lunr.stemmer.support.min.js></script><script src=/lib/lunr/lunr.it.min.js></script><script src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js></script><script>window.config={comment:{},search:{highlightTag:"em",lunrIndexURL:"/it/index.json",lunrLanguageCode:"it",maxResultLength:10,noResultsFound:"Nessun risultato trovato",snippetLength:30,type:"lunr"}}</script><script src=/js/theme.min.js></script><script>var dnt,doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8NZQZ3Z1RN")}</script><script src="https://www.googletagmanager.com/gtag/js?id=G-8NZQZ3Z1RN" async></script></body></html>