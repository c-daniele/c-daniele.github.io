<!doctype html><html lang=it dir=ltr><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Langchain pt. 2 - Analisi dati tramite Agenti | Cdani's Blog</title><meta name=keywords content="ai,langchain,agents"><meta name=description content="Intro Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d&rsquo;uso con dati non strutturati in formato pdf.
Seguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:
è possibile, tramite l&rsquo;AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?"><meta name=author content="Me"><link rel=canonical href=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.3598bbf45621a4ad34d093926efeb15d6df27175e085d2f069483f14ad39d7fa.css integrity="sha256-NZi79FYhpK000JOSbv6xXW3ycXXghdLwaUg/FK051/o=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=it href=https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/><link rel=alternate hreflang=en href=https://c-daniele.github.io/en/posts/2023-08-13-langchain-agents/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0,theme:"default",securityLevel:"loose"})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-8NZQZ3Z1RN"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8NZQZ3Z1RN",{anonymize_ip:!1})}</script><meta property="og:title" content="Langchain pt. 2 - Analisi dati tramite Agenti"><meta property="og:description" content="Intro Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d&rsquo;uso con dati non strutturati in formato pdf.
Seguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:
è possibile, tramite l&rsquo;AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?"><meta property="og:type" content="article"><meta property="og:url" content="https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/"><meta property="og:image" content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-13T19:00:00+02:00"><meta property="article:modified_time" content="2023-08-13T19:00:00+02:00"><meta property="og:site_name" content="Cdani's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Langchain pt. 2 - Analisi dati tramite Agenti"><meta name=twitter:description content="Intro Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d&rsquo;uso con dati non strutturati in formato pdf.
Seguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:
è possibile, tramite l&rsquo;AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":4,"name":"Langchain pt. 2 - Analisi dati tramite Agenti","item":"https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Langchain pt. 2 - Analisi dati tramite Agenti","name":"Langchain pt. 2 - Analisi dati tramite Agenti","description":"Intro Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d\u0026rsquo;uso con dati non strutturati in formato pdf.\nSeguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:\nè possibile, tramite l\u0026rsquo;AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?","keywords":["ai","langchain","agents"],"articleBody":"Intro Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d’uso con dati non strutturati in formato pdf.\nSeguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:\nè possibile, tramite l’AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?\nAgenti I LLM sono estremamente potenti, ma possono rivelarsi inefficaci nel rispondere a domande che richiedono una conoscenza di dettaglio non strettamente integrata nel training del modello. In rete esistono decine di esempi che riescono a cogliere in fallo ChatGPT tramite allucinazioni o mancata risposta (es: previsioni meteo, ultime notizie, gossip o anche operazioni matematiche particolari).\nI framework come LangChain possono superare queste limitazioni tramite la definizione di componenti specifici e “data-aware”, ma solitamente le azioni eseguite dal framework sono predeterminate. In altre parole, il framework utilizza un Language Model per eseguire delle azioni, ma esse sono “hardcoded” e in moltissimi casi questo può rendere del tutto inefficaci i modelli di AI, perché non si riesce ad aggiungere quel livello di dinamismo tale da pilotare le specifiche azioni sulla base dell’input utente.\nE’ qui che entrano in gioco gli “Agent”. Gli Agent sono dei componenti che hanno a disposizione una serie di Tool per svolgere delle azioni specifiche, come ad esempio fare una ricerca su Wikipedia o su Google, o eseguire codice Python o addirittura accedere al file system locale.\nGli Agent utilizzano un LLM per interpretare l’input dell’utente e decidere di volta come procedere, cioè:\nQuale tool utilizzare tra gli N a disposizione Cosa passare come input al tool Decidere se si è riusciti ad ottenere una risposta al quesito iniziale oppure ripetere gli step 1 e 2 Questo approccio prende ispirazione da un framework denominato ReAct che è stato definito a fine 2022 da un team congiunto di ricercatori di Google e della Princeton University, che trovate descritto qui. In LangChain, ne esistono diverse implementazioni, ma la più comune prende il nome di “Zero-shot ReAct” e può essere schematizzata secondo il workflow in Figura 1.\nFigura 1 - Workflow semplificato per gli agenti di tipo \"Zero-shot ReAct\" Un aspetto particolarmente rilevante da tenere in considerazione è relativo al fatto che gli agenti di questo tipo non hanno memoria e discriminano le loro azioni unicamente sulla base del testo in input e della descrizione del tool. E’ dunque importante che i tool includano anche una descrizione efficace ai fini di una corretta interpretazione da parte del LLM.\nPer semplicità, i tool di LangChain sono talvolta raggruppati in gruppi denominati “Toolkits”. Nella documentazione ufficiale troverete un toolkit predefinito che si chiama “SQLDatabaseToolkit”, per configurare appunto un agente SQL.\nLa descrizione dello scenario Come preannunciato all’inizio dell’articolo, vogliamo fare una vera e propria analisi in maniera automatica sui dati presenti in un DB relazionale, supponendo di non avere alcuna conoscenza del modello dati né tantomeno competenze SQL. Il punto di partenza sarà infatti un prompt testuale in lingua naturale.\nDa un punto di vista tecnico, l’esercizio è facilissimo perché, oltre al toolkit, LangChain mette a disposizione un metodo di utility per la definizione di un SqlAgent in cui dobbiamo passare solo alcuni parametri come i puntamenti al DB, il tipo di LLM, etc..\nA prima vista, gli esempi riportati nella documentazione ufficiale sembrano già molto interessanti. Oltre ai casi banali (es: DESCRIBE di una tabella), viene infatti mostrato come l’agente sia in grado di fare inferenza sui metadati per capire come aggregare i dati o mettere in JOIN 2 o più tabelle. Tutto ciò in totale autonomia.\nPer non ripetere lo stesso identico esempio presente nella documentazione ed introdurre qualche complicazione in più, decido di creare una versione potenziata del toolkit standard, che sia in grado di fare anche ricerche su Google.\nIl dataset La documentazione ufficiale include degli esempi che fanno uso di un DB di prova basato su SqlLite e denominato “Chinook”, che simula un media store e che trovate anche nel sito ufficiale di SqlLite.\nDando un occhio al modello dati e ai dati stessi, ho guardato con sospetto gli entusiasmanti risultati che hanno riportato, perché il DB è a mio avviso non è rappresentativo di un caso reale:\ni nomi delle tabelle e delle colonne sono tutti abbastanza parlanti ed in lingua inglese, inoltre non viene fatto uso di una naming convention il DB sembra praticamente in terza forma normale: improbabile laddove si voglia fare pura analisi dati file .db SqlLite in locale? Si tratta di un caso molto lontano dalla realtà! Fortunatamente ho a disposizione un DB Athena su un mio account AWS con alcune strutture dati più vicine ad un caso reale e di cui conosco un po’ la semantica del dato. Si tratta di OpenData del Comune di Milano, relativi ai transiti all’interno dei varchi di AreaC. In realtà Athena non è un vero DB, quanto piuttosto un SQL-Engine basato su Presto, ma con le opportune configurazioni, AWS mette a disposizione un endpoint che permette di accedervi come se fosse un vero DBMS.\nIl Data Model è semplicissimo: si tratta di 2 tabelle dei fatti, che fanno riferimento al conteggio degli ingressi (dettaglio+aggregato), legate entrambe ad una tabella di decodifica dei varchi, in cui sono indicati alcuni attributi tra cui la posizione geografica esatta del varco. In tutti e 3 i casi, si tratta di tabelle Iceberg memorizzate su S3 e mappate su Athena tramite il catalogo di Glue.\nI dataset originari li trovate sul portale OpenData ufficiale. Si tratta di circa 4 anni di dati (circa 101 milioni di record nella tabella di cardinalità massima).\nDi seguito le DDL delle tabelle con qualche commento che ho aggiunto qui per semplicità (e che dunque l’agente non aveva a disposizione…).\nFigura 2 - DDL tabella di dettaglio Figura 3 - DDL tabella aggregata Figura 2 - DDL tabella di decodifica dei varchi Nella tabella aggregata, oltre a rimuovere qualche attributo, ho fatto una sorta di pivot sul tipo di alimentazione, calcolando i diversi transiti in COLONNA anziché in RIGA, riducendo la cardinalità di circa il 92%. A parte questo, le 2 tabelle dei fatti sono praticamente identiche.\nLa tabella di decodifica dei varchi, oltre al nome descrittivo, contiene anche le coordinate geografiche.\nCome si può vedere, ho usato una naming convention, ma essa è volutamente imperfetta, ad esempio è un mix di inglese ed italiano.\nLa configurazione software Riporto di seguito gli import e le configurazioni di base del codice python:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 from langchain.agents import create_sql_agent from langchain.sql_database import SQLDatabase from langchain.llms.openai import OpenAI from langchain.agents.agent_types import AgentType import os from urllib.parse import quote_plus from ExtendedSqlDatabaseToolkit import * # carico le variabili di ambiente from dotenv import load_dotenv load_dotenv() # connection string conn_str = ( \"awsathena+rest://{aws_access_key_id}:{aws_secret_access_key}@\" \"athena.{region_name}.amazonaws.com:443/\" \"{schema_name}?s3_staging_dir={s3_staging_dir}\u0026work_group={wg}\" ) # inizializzazione del DB db = SQLDatabase.from_uri(conn_str.format( aws_access_key_id=quote_plus(os.environ['AWS_AK']), aws_secret_access_key=quote_plus(os.environ['AWS_SAK']), region_name=os.environ['AWS_REGION'], schema_name=os.environ['AWS_ATHENA_SCHEMA'], s3_staging_dir=quote_plus(os.environ['AWS_S3_OUT']), wg=os.environ['AWS_ATHENA_WG'] ) , include_tables=['xtdpl1_ingressi_detailed', 'xtdpl1_ingressi_aggregated', 'xtdpl1_varchi'] , sample_rows_in_table_info=2) # definizione del toolkit tramite classe Custom toolkit = ExtendedSqlDatabaseToolkit(db=db, llm=OpenAI(temperature=0)) # inizializzazione dell'Agent agent_executor = create_sql_agent( llm=OpenAI(temperature=0), toolkit=toolkit, verbose=True, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION ) LangChain utilizza SQLAlchemy quindi garantisce già l’accesso a un gran numero di DBMS senza la necessità di inventarsi nulla.\nDa notare che oltre alle variabili di ambiente relative ad AWS ed esplicitamente referenziate sopra, occorre anche settare le variabili:\nOPENAI_API_KEY: associata all’account OpenAI, essenziale per l’utilizzo del LLM SERPAPI_API_KEY: associata all’account SerpApi, al fine di fare programmaticamente ricerche su Google. Esiste una versione FREE che supporta un numero di chiamate mensili \u003c 100 Le opzioni indicate in riga 29 e 30 servono per limitare il raggio d’azione dell’agente ed evitare che faccia ragionamenti troppo estesi su tutto il catalogo o su un sample di dati troppo ampio. Il rischio è infatti quello di saturare molto facilmente i token disponibili dal LLM.\nIl toolkit istanziato in riga 34 è una mia classe custom, che estende il SQLToolkit standard messo a disposizione da LangChain. Trattandosi di poche righe di codice, aggiungo anche questo:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \"\"\"Enhanced Toolkit for interacting with SQL databases and search over the internet\"\"\" from typing import List from langchain.agents.agent_toolkits import SQLDatabaseToolkit from langchain.tools import BaseTool from langchain.agents import load_tools class ExtendedSqlDatabaseToolkit(SQLDatabaseToolkit): \"\"\"Enhanced Toolkit for interacting with SQL databases and search over the internet\"\"\" def get_tools(self) -\u003e List[BaseTool]: sqlTools = super().get_tools() additionalTools = load_tools([\"serpapi\"], llm=self.llm) return additionalTools+sqlTools Oltre alle librerie esplicitamente referenziate, occorre anche installare le librerie “openai” e “pyathena”.\nLe challenges Ho sottoposto all’agente diverse domande, cercando di stressare le diverse componenti (es: capacità di individuare la semantica del dato, capire cosa cercare su google, quando/se andare nella tabella di dettaglio, etc etc).\nMi limiterò nel seguito a descrivere un paio di esempi, ma prima faccio qualche considerazione generale.\nIl modello standard utilizzato dalle librerie OpenAI è Text-davinci-003. Questo modello, è molto più ampio e più costoso (circa 10 volte di più!) di quello usato da ChatGPT (GPT-3.5-Turbo). Esiste molta letteratura che descrive l’efficacia di entrambi e di come il secondo, pur essendo sulla carta più piccolo (6 vs 175 miliardi di parametri), possa comunque avere risultati uguali o in alcuni casi addirittura migliori.\nPersonalmente ho usato quasi esclusivamente il primo dei 2 e le poche prove che ho fatto con GPT-3.5-Turbo hanno avuto risultati nettamente peggiori, ma non ho approfondito molto questo aspetto, a cui magari dedicherò un altro articolo.\nCaso A - Calcolo di un semplice KPI trova le coordinate e il nome descrittivo del varco in cui ci sono più transiti di veicoli diesel nel periodo di Agosto 2020. Considera gli ingressi effettivamente areac ed escludi i mezzi di servizio\nL’output restituito è indicato in Figura 3 e se date un occhio alle righe che iniziano per “Action”, “Observation” e “Thought”, vedrete che esso rispetta quanto previsto nel modello “Zero-shot ReAct”.\nFigura 3 - Output caso A In particolare, l’agente parte con l’identificazione della Action (sql_db_list_tables) e dell’input (nessun in input in questo caso), ottenendo (Observation) le 3 tabelle su cui abbiamo programmaticamente ristretto la sua visibilità. In teoria il tool potrebbe esplorare tutto il catalogo ma, come anticipato sopra, ho voluto restringere il campo per evitare di saturare i token messi a disposizione del modello.\nA questo punto l’agente passa il controllo al LLM (Thought) per decidere la prossima azione e tramite esso determina che le uniche 2 tabelle di interesse sono la tabella dei fatti aggregata e la tabella di decodifica dei varchi.\nE’ interessante che già in questa fase abbia dedotto che sia meglio fare la query sulla tabella aggregata rispetto a quella di dettaglio, ma mi stranisce un po’ il fatto che abbia fatto questa deduzione basandosi unicamente sulla naming della tabella, poiché l’inferenza sui metadati e sui dati viene fatta solo in un momento successivo. In tal senso, il risultato finale potrebbe non essere quello corretto qualora le 2 tabelle avessero avuto un perimetro dati diverso (ad esempio qualora la tabella aggregata contenesse solo l’ultimo anno).\nDopo aver letto i metadati e fatto un carotaggio dei dati, il LLM costruisce la query. In questo caso specifico si vede chiaramente che il modello indovina la sintassi della query al primo tentativo, ma ho sperimentato diversi casi in cui esso va a tentativi, correggendo di volta in volta la sintassi fino ad arrivare alla query definitiva (vedi casi B e C).\nIl resto è autodescritto nell’immagine.\nUn paio di commenti:\nil modello è riuscito a implementare perfettamente i filtri che avevo in mente nel prompt, tramite inferenza sulla naming e/o sui dati ho fatto altri tentativi rimuovendo la tabella aggregata e lasciando solo quella di dettaglio e ho ottenuto lo stesso risultato. Da notare però che la tabella di dettaglio ha il KPI in riga anziché in colonna, dunque in quel caso il modello ha capito che andava applicato il filtro “des_tipo_alimentazione = ‘diesel’” come da attese, non è stata fatta alcuna ricerca su google, perché ovviamente non serviva Caso B - informazioni aggiuntive trova il varco in cui ci sono più transiti di veicoli diesel nel periodo di Agosto 2020, includendo solo ingressi areac ed escludendo i mezzi di servizio. Restituiscimi anche i 3 varchi più vicini ad esso\nQui, il LLM mi ha sorpreso: ho aggiunto la frase finale per costringerlo a fare una ricerca su Google, ma non avevo pensato che partendo dalle coordinate geografiche fosse possibile calcolare la distanza con delle operazioni matematiche, dunque il tool (e cioè il modello LLM sottostante) ha eseguito l’intero task all’interno del DB tramite le funzioni ST_POINT ed ST_DISTANCE come mostrato in Figura 8.\nHo omesso la prima parte dell’output perché identica al caso precedente.\nFigura 4 - Output caso B Come si vede dai vari messaggi di errore, in questo caso il modello ha avuto diverse “allucinazioni” nella costruzione della query SQL, ma è riuscito a correggerli fino ad arrivare alla query definitiva perché l’agente ha restituito al modello LLM i feedback di tali errori tramite i loop Action-Observation-Thought.\nCaso C - esecuzione combinata SQL+Ricerca L’estrema semplicità del modello dati non mi ha aiutato molto nel creare una richiesta sufficientemente articolata, dunque ho dovuto fare un po’ di prompt engineering per costringerlo a fare una ricerca sul web. Alla fine sono riuscito ad ottenere qualcosa con una richiesta di questo tipo:\ntrova le coordinate e il nome descrittivo del varco in cui ci sono più transiti di veicoli diesel nel mese di Agosto 2020. Cerca la fermata dei mezzi pubblici più vicina a quel varco\nQui sono accadute 2 cose strane:\nnonostante la prima parte del prompt fosse quasi identica al caso A (ho usato “nel mese di” anziché “nel periodo di”), il LLM esegue l’operazione di MAX anziché di SUM come da attese, l’agente ha eseguito la ricerca tramite SerpApi per individuare la fermata dei mezzi ma, anziché usare le coordinate, ha usato il nome descrittivo del varco. Il risultato chiaramente non è in linea con le aspettative, perché viene restituita una fermata dei mezzi della città di Venezia Figura 4 - Output caso C Conclusioni Come già ho scritto nel precedente articolo, la curva di apprendimento per adottare LangChain è piuttosto bassa. Bastano poche righe di codice per ottenere un effetto “wow” e consentire a chiunque di implementare una propria soluzione custom, magari integrata con il resto dell’ecosistema aziendale (repository documentali, Data APIs, mail server, shared file systems, …) e/o con il proprio LLM (ad esempio, è possibile integrare una propria installazione di Llama 2 on-premise) laddove non si vogliano condividere dati al di fuori dell’organizzazione aziendale.\nD’altro canto, gli esempi che ho riportato sopra sono da considerarsi come tutorial semplificati per prendere dimestichezza con il framework.\nPer mettere a terra delle soluzioni reali, serve un approccio più strutturato, che sfrutti meglio le caratteristiche del framework e tenga conto delle peculiarità dei modelli.\nAd esempio, mi sono reso conto che non è stata una scelta saggia quella di unire le funzionalità SQL e di ricerca SerpApi in un unico toolkit e che sarebbe stato meglio integrare le 2 funzionalità tramite agent/chain separati.\nCome altro esempio, ho notato che nel pacchetto “experimental” è presente una classe che si chiama “SQLDatabaseChain” che con poche righe di codice permette di sviluppare un Tool Sql from scratch, bypassando completamente il toolkit standard:\n1 2 3 4 5 6 7 8 9 10 11 12 sql_chain = SQLDatabaseChain.from_llm(llm=llm, db=db, verbose=True) sql_tool = Tool( name='Areac DB', func=sql_chain.run, description=\"Database che contiene i dati relativi agli ingressi nei varchi dell'area C di Milano.\" \" Le tabelle principali sono xtdpl1_ingressi_aggregated e xtdpl1_varchi.\" \" La tabella xtdpl1_ingressi_aggregated contiene le principali misure, come ad esempio il conteggio del numero di accessi per ciascuno dei varchi e per ciascun giorno dell'anno.\" \" Il campo relativo alla dimensione tempo si chiama dat_year_month ed è di tipo numerico, nel classico formato YYYYMM.\" \" Il campo flg_areac è di tipo BOOLEAN (true/false) ed indica se si tratta di un ingresso effettivamente conteggiato come areac.\" \" La tabella xtdpl1_varchi contiene la decodifica dei varchi. La chiave principale di questa tabella è il campo 'id', che identifica il varco. Gli altri attributi sono descrittivi.\" ) Poiché l’agente utilizza il LLM per decidere QUALE tool utilizzare e COME utilizzarlo unicamente in base alla descrizione del tool, questo approccio ha il grande vantaggio di migliorare le performance semplicemente aggiungendo una descrizione efficace del DB all’interno del tool, senza modificare in alcun modo il modello LLM. Nel mio caso, ad esempio, ho aggiunto incrementalmente un gran numero di dettagli e ho notato un progressivo miglioramento delle performance.\n","wordCount":"2803","inLanguage":"it","datePublished":"2023-08-13T19:00:00+02:00","dateModified":"2023-08-13T19:00:00+02:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://c-daniele.github.io/it/posts/2023-08-13-langchain-agents/"},"publisher":{"@type":"Organization","name":"Cdani's Blog","logo":{"@type":"ImageObject","url":"https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://c-daniele.github.io/it/ accesskey=h title="Home (Alt + H)"><img src=https://c-daniele.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://c-daniele.github.io/en/ title=English aria-label=English>En</a></li></ul></div></div><ul id=menu><li><a href=https://c-daniele.github.io/it/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://c-daniele.github.io/it/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://c-daniele.github.io/it/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://c-daniele.github.io/it/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://c-daniele.github.io/it/>Home</a></div><h1 class=post-title>Langchain pt. 2 - Analisi dati tramite Agenti</h1><div class=post-meta><span title='2023-08-13 19:00:00 +0200 +0200'>agosto 13, 2023</span>&nbsp;·&nbsp;14 minuti&nbsp;·&nbsp;2803 parole&nbsp;·&nbsp;Me&nbsp;|&nbsp;Traduzioni:<ul class=i18n_list><li><a href=https://c-daniele.github.io/en/posts/2023-08-13-langchain-agents/>En</a></li></ul></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Indice contenuti</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#agenti>Agenti</a></li><li><a href=#e-qui-che-entrano-in-gioco-gli-agent>E&rsquo; qui che entrano in gioco gli &ldquo;Agent&rdquo;.</a></li><li><a href=#la-descrizione-dello-scenario>La descrizione dello scenario</a><ul><li><a href=#il-dataset>Il dataset</a></li><li><a href=#la-configurazione-software>La configurazione software</a></li></ul></li><li><a href=#le-challenges>Le challenges</a><ul><li><a href=#caso-a---calcolo-di-un-semplice-kpi>Caso A - Calcolo di un semplice KPI</a></li><li><a href=#caso-b---informazioni-aggiuntive>Caso B - informazioni aggiuntive</a></li><li><a href=#caso-c---esecuzione-combinata-sqlricerca>Caso C - esecuzione combinata SQL+Ricerca</a></li></ul></li><li><a href=#conclusioni>Conclusioni</a></li></ul></nav></div></details></div><div class=post-content><h2 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h2><p>Nel precedente articolo ho fatto una brevissima panoramica di LangChain, descrivendone i concetti principali e raccontando un esempio di caso d&rsquo;uso con dati non strutturati in formato pdf.</p><p>Seguendo lo stesso approccio, in questo articolo faremo una breve introduzione sugli Agenti e procederemo provando a rispondere ad una domanda ambiziosa:</p><blockquote><p>è possibile, tramite l&rsquo;AI, fare analisi sui dati presenti in un DB senza alcuna conoscenza di SQL né tantomeno del modello dati, a partire semplicemente da un prompt testuale in lingua naturale?</p></blockquote><h2 id=agenti>Agenti<a hidden class=anchor aria-hidden=true href=#agenti>#</a></h2><p>I LLM sono estremamente potenti, ma possono rivelarsi inefficaci nel rispondere a domande che richiedono una conoscenza di dettaglio non strettamente integrata nel training del modello. In rete esistono decine di esempi che riescono a cogliere in fallo ChatGPT tramite allucinazioni o mancata risposta (es: previsioni meteo, ultime notizie, gossip o anche operazioni matematiche particolari).</p><p>I framework come LangChain possono superare queste limitazioni tramite la definizione di componenti specifici e &ldquo;data-aware&rdquo;, ma solitamente le azioni eseguite dal framework sono predeterminate. In altre parole, <strong>il framework utilizza un Language Model per eseguire delle azioni, ma esse sono &ldquo;hardcoded&rdquo;</strong> e in moltissimi casi questo può rendere del tutto inefficaci i modelli di AI, perché non si riesce ad aggiungere quel livello di dinamismo tale da pilotare le specifiche azioni sulla base dell&rsquo;input utente.</p><h2 id=e-qui-che-entrano-in-gioco-gli-agent>E&rsquo; qui che entrano in gioco gli &ldquo;Agent&rdquo;.<a hidden class=anchor aria-hidden=true href=#e-qui-che-entrano-in-gioco-gli-agent>#</a></h2><p>Gli Agent sono dei componenti che hanno a disposizione una serie di Tool per svolgere delle azioni specifiche, come ad esempio fare una ricerca su Wikipedia o su Google, o eseguire codice Python o addirittura accedere al file system locale.</p><p>Gli Agent utilizzano un LLM per interpretare l&rsquo;input dell&rsquo;utente e decidere di volta come procedere, cioè:</p><ol><li>Quale tool utilizzare tra gli N a disposizione</li><li>Cosa passare come input al tool</li><li>Decidere se si è riusciti ad ottenere una risposta al quesito iniziale oppure ripetere gli step 1 e 2</li></ol><p>Questo approccio prende ispirazione da un framework denominato ReAct che è stato definito a fine 2022 da un team congiunto di ricercatori di Google e della Princeton University, che trovate <a href=https://arxiv.org/abs/2210.03629>descritto qui</a>. In LangChain, ne esistono diverse implementazioni, ma la più comune prende il nome di &ldquo;<em>Zero-shot ReAct</em>&rdquo; e può essere schematizzata secondo il workflow in Figura 1.</p><figure><img loading=lazy src=/images/20230813/Agent_Diagram_v2.png><figcaption>Figura 1 - Workflow semplificato per gli agenti di tipo "Zero-shot ReAct"</figcaption></figure><p>Un aspetto particolarmente rilevante da tenere in considerazione è relativo al fatto che gli agenti di questo tipo non hanno memoria e discriminano le loro azioni <strong>unicamente sulla base del testo in input e della descrizione del tool</strong>. E&rsquo; dunque importante che i tool includano anche una descrizione efficace ai fini di una corretta interpretazione da parte del LLM.</p><p>Per semplicità, i tool di LangChain sono talvolta raggruppati in gruppi denominati &ldquo;Toolkits&rdquo;. Nella documentazione ufficiale troverete un toolkit predefinito che si chiama &ldquo;SQLDatabaseToolkit&rdquo;, per configurare appunto un agente SQL.</p><h2 id=la-descrizione-dello-scenario>La descrizione dello scenario<a hidden class=anchor aria-hidden=true href=#la-descrizione-dello-scenario>#</a></h2><p>Come preannunciato all&rsquo;inizio dell&rsquo;articolo, vogliamo fare una vera e propria analisi in maniera automatica sui dati presenti in un DB relazionale, supponendo di non avere alcuna conoscenza del modello dati né tantomeno competenze SQL. Il punto di partenza sarà infatti un prompt testuale in lingua naturale.</p><p>Da un punto di vista tecnico, l&rsquo;esercizio è facilissimo perché, oltre al toolkit, LangChain mette a disposizione un metodo di utility per la definizione di un SqlAgent in cui dobbiamo passare solo alcuni parametri come i puntamenti al DB, il tipo di LLM, etc..</p><p>A prima vista, <a href=https://python.langchain.com/docs/integrations/toolkits/sql_database>gli esempi riportati nella documentazione ufficiale</a> sembrano già molto interessanti. Oltre ai casi banali (es: DESCRIBE di una tabella), viene infatti mostrato come l&rsquo;agente sia in grado di fare inferenza sui metadati per capire come aggregare i dati o mettere in JOIN 2 o più tabelle. Tutto ciò in totale autonomia.</p><p>Per non ripetere lo stesso identico esempio presente nella documentazione ed introdurre qualche complicazione in più, decido di creare una versione potenziata del toolkit standard, che sia in grado di fare anche ricerche su Google.</p><h3 id=il-dataset>Il dataset<a hidden class=anchor aria-hidden=true href=#il-dataset>#</a></h3><p>La documentazione ufficiale include degli esempi che fanno uso di un DB di prova basato su SqlLite e denominato &ldquo;Chinook&rdquo;, che simula un media store e che trovate anche nel sito ufficiale di SqlLite.</p><p>Dando un occhio al modello dati e ai dati stessi, ho guardato con sospetto gli entusiasmanti risultati che hanno riportato, perché il DB è a mio avviso non è rappresentativo di un caso reale:</p><ul><li>i nomi delle tabelle e delle colonne sono tutti abbastanza parlanti ed in lingua inglese, inoltre non viene fatto uso di una naming convention</li><li>il DB sembra praticamente in terza forma normale: improbabile laddove si voglia fare pura analisi dati</li><li>file .db SqlLite in locale? Si tratta di un caso molto lontano dalla realtà!</li></ul><p>Fortunatamente ho a disposizione un DB Athena su un mio account AWS con alcune strutture dati più vicine ad un caso reale e di cui conosco un po&rsquo; la semantica del dato. Si tratta di OpenData del Comune di Milano, relativi ai <strong>transiti all&rsquo;interno dei varchi di AreaC</strong>. In realtà Athena non è un vero DB, quanto piuttosto un SQL-Engine basato su Presto, ma con le opportune configurazioni, AWS mette a disposizione un endpoint che permette di accedervi come se fosse un vero DBMS.</p><p>Il Data Model è semplicissimo: si tratta di 2 tabelle dei fatti, che fanno riferimento al conteggio degli ingressi (dettaglio+aggregato), legate entrambe ad una tabella di decodifica dei varchi, in cui sono indicati alcuni attributi tra cui la posizione geografica esatta del varco. In tutti e 3 i casi, si tratta di tabelle Iceberg memorizzate su S3 e mappate su Athena tramite il catalogo di Glue.</p><p>I dataset originari li trovate sul <a href=https://dati.comune.milano.it/group/tran>portale OpenData ufficiale</a>. Si tratta di circa 4 anni di dati (circa 101 milioni di record nella tabella di cardinalità massima).</p><p>Di seguito le DDL delle tabelle con qualche commento che ho aggiunto qui per semplicità (e che dunque l&rsquo;agente non aveva a disposizione&mldr;).</p><figure><img loading=lazy src=/images/20230813/screenshot1.png><figcaption>Figura 2 - DDL tabella di dettaglio</figcaption></figure><figure><img loading=lazy src=/images/20230813/screenshot2.png><figcaption>Figura 3 - DDL tabella aggregata</figcaption></figure><figure><img loading=lazy src=/images/20230813/screenshot3.png><figcaption>Figura 2 - DDL tabella di decodifica dei varchi</figcaption></figure><p>Nella tabella aggregata, oltre a rimuovere qualche attributo, ho fatto una sorta di pivot sul tipo di alimentazione, calcolando i diversi transiti in COLONNA anziché in RIGA, riducendo la cardinalità di circa il 92%. A parte questo, le 2 tabelle dei fatti sono praticamente identiche.</p><p>La tabella di decodifica dei varchi, oltre al nome descrittivo, contiene anche le coordinate geografiche.</p><p>Come si può vedere, ho usato una naming convention, ma essa è <strong>volutamente imperfetta</strong>, ad esempio è un mix di inglese ed italiano.</p><h3 id=la-configurazione-software>La configurazione software<a hidden class=anchor aria-hidden=true href=#la-configurazione-software>#</a></h3><p>Riporto di seguito gli import e le configurazioni di base del codice python:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents</span> <span class=kn>import</span> <span class=n>create_sql_agent</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.sql_database</span> <span class=kn>import</span> <span class=n>SQLDatabase</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.llms.openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents.agent_types</span> <span class=kn>import</span> <span class=n>AgentType</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>urllib.parse</span> <span class=kn>import</span> <span class=n>quote_plus</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ExtendedSqlDatabaseToolkit</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># carico le variabili di ambiente</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># connection string</span>
</span></span><span class=line><span class=cl><span class=n>conn_str</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;awsathena+rest://</span><span class=si>{aws_access_key_id}</span><span class=s2>:</span><span class=si>{aws_secret_access_key}</span><span class=s2>@&#34;</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;athena.</span><span class=si>{region_name}</span><span class=s2>.amazonaws.com:443/&#34;</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;</span><span class=si>{schema_name}</span><span class=s2>?s3_staging_dir=</span><span class=si>{s3_staging_dir}</span><span class=s2>&amp;work_group=</span><span class=si>{wg}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># inizializzazione del DB</span>
</span></span><span class=line><span class=cl><span class=n>db</span> <span class=o>=</span> <span class=n>SQLDatabase</span><span class=o>.</span><span class=n>from_uri</span><span class=p>(</span><span class=n>conn_str</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>aws_access_key_id</span><span class=o>=</span><span class=n>quote_plus</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_AK&#39;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>aws_secret_access_key</span><span class=o>=</span><span class=n>quote_plus</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_SAK&#39;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>region_name</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_REGION&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>schema_name</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_ATHENA_SCHEMA&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>s3_staging_dir</span><span class=o>=</span><span class=n>quote_plus</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_S3_OUT&#39;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>wg</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;AWS_ATHENA_WG&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl> <span class=p>,</span> <span class=n>include_tables</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;xtdpl1_ingressi_detailed&#39;</span><span class=p>,</span> <span class=s1>&#39;xtdpl1_ingressi_aggregated&#39;</span><span class=p>,</span> <span class=s1>&#39;xtdpl1_varchi&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl> <span class=p>,</span> <span class=n>sample_rows_in_table_info</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># definizione del toolkit tramite classe Custom</span>
</span></span><span class=line><span class=cl><span class=n>toolkit</span> <span class=o>=</span> <span class=n>ExtendedSqlDatabaseToolkit</span><span class=p>(</span><span class=n>db</span><span class=o>=</span><span class=n>db</span><span class=p>,</span> <span class=n>llm</span><span class=o>=</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># inizializzazione dell&#39;Agent</span>
</span></span><span class=line><span class=cl><span class=n>agent_executor</span> <span class=o>=</span> <span class=n>create_sql_agent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>llm</span><span class=o>=</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>toolkit</span><span class=o>=</span><span class=n>toolkit</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>agent_type</span><span class=o>=</span><span class=n>AgentType</span><span class=o>.</span><span class=n>ZERO_SHOT_REACT_DESCRIPTION</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>LangChain utilizza SQLAlchemy quindi garantisce già l&rsquo;accesso a un gran numero di DBMS senza la necessità di inventarsi nulla.</p><p>Da notare che oltre alle variabili di ambiente relative ad AWS ed esplicitamente referenziate sopra, occorre anche settare le variabili:</p><ul><li>OPENAI_API_KEY: associata all&rsquo;account OpenAI, essenziale per l&rsquo;utilizzo del LLM</li><li>SERPAPI_API_KEY: associata all&rsquo;account SerpApi, al fine di fare programmaticamente ricerche su Google. Esiste una versione FREE che supporta un numero di chiamate mensili &lt; 100</li></ul><p>Le opzioni indicate in riga 29 e 30 servono per limitare il raggio d&rsquo;azione dell&rsquo;agente ed evitare che faccia ragionamenti troppo estesi su tutto il catalogo o su un sample di dati troppo ampio. Il rischio è infatti quello di saturare molto facilmente i token disponibili dal LLM.</p><p>Il toolkit istanziato in riga 34 è una mia classe custom, che estende il SQLToolkit standard messo a disposizione da LangChain. Trattandosi di poche righe di codice, aggiungo anche questo:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;Enhanced Toolkit for interacting with SQL databases and search over the internet&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>List</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents.agent_toolkits</span> <span class=kn>import</span> <span class=n>SQLDatabaseToolkit</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.tools</span> <span class=kn>import</span> <span class=n>BaseTool</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents</span> <span class=kn>import</span> <span class=n>load_tools</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ExtendedSqlDatabaseToolkit</span><span class=p>(</span><span class=n>SQLDatabaseToolkit</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Enhanced Toolkit for interacting with SQL databases and search over the internet&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_tools</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>BaseTool</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>sqlTools</span> <span class=o>=</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=n>get_tools</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>additionalTools</span> <span class=o>=</span> <span class=n>load_tools</span><span class=p>([</span><span class=s2>&#34;serpapi&#34;</span><span class=p>],</span> <span class=n>llm</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>llm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>additionalTools</span><span class=o>+</span><span class=n>sqlTools</span>
</span></span></code></pre></td></tr></table></div></div><p>Oltre alle librerie esplicitamente referenziate, occorre anche installare le librerie &ldquo;openai&rdquo; e &ldquo;pyathena&rdquo;.</p><h2 id=le-challenges>Le challenges<a hidden class=anchor aria-hidden=true href=#le-challenges>#</a></h2><p>Ho sottoposto all&rsquo;agente diverse domande, cercando di stressare le diverse componenti (es: capacità di individuare la semantica del dato, capire cosa cercare su google, quando/se andare nella tabella di dettaglio, etc etc).</p><p>Mi limiterò nel seguito a descrivere un paio di esempi, ma prima faccio qualche considerazione generale.</p><p>Il modello standard utilizzato dalle librerie OpenAI è <em>Text-davinci-003</em>. Questo modello, è molto più ampio e più costoso (circa 10 volte di più!) di quello usato da ChatGPT (<em>GPT-3.5-Turbo</em>). Esiste molta letteratura che descrive l&rsquo;efficacia di entrambi e di come il secondo, pur essendo sulla carta più piccolo (6 vs 175 miliardi di parametri), possa comunque avere risultati uguali o in alcuni casi addirittura migliori.</p><p>Personalmente ho usato quasi esclusivamente il primo dei 2 e le poche prove che ho fatto con GPT-3.5-Turbo hanno avuto risultati nettamente peggiori, ma non ho approfondito molto questo aspetto, a cui magari dedicherò un altro articolo.</p><h3 id=caso-a---calcolo-di-un-semplice-kpi>Caso A - Calcolo di un semplice KPI<a hidden class=anchor aria-hidden=true href=#caso-a---calcolo-di-un-semplice-kpi>#</a></h3><blockquote><p><em>trova le coordinate e il nome descrittivo del varco in cui ci sono più transiti di veicoli diesel nel periodo di Agosto 2020. Considera gli ingressi effettivamente areac ed escludi i mezzi di servizio</em></p></blockquote><p>L&rsquo;output restituito è indicato in Figura 3 e se date un occhio alle righe che iniziano per &ldquo;Action&rdquo;, &ldquo;Observation&rdquo; e &ldquo;Thought&rdquo;, vedrete che esso rispetta quanto previsto nel modello &ldquo;Zero-shot ReAct&rdquo;.</p><figure><img loading=lazy src=/images/20230813/screenshot6_result_1.png><figcaption>Figura 3 - Output caso A</figcaption></figure><p>In particolare, l&rsquo;agente parte con l&rsquo;identificazione della <strong>Action</strong> (sql_db_list_tables) e dell&rsquo;input (nessun in input in questo caso), ottenendo (<strong>Observation</strong>) le 3 tabelle su cui abbiamo programmaticamente ristretto la sua visibilità. In teoria il tool potrebbe esplorare tutto il catalogo ma, come anticipato sopra, ho voluto restringere il campo per evitare di saturare i token messi a disposizione del modello.</p><p>A questo punto l&rsquo;agente passa il controllo al LLM (<strong>Thought</strong>) per decidere la prossima azione e tramite esso determina che le uniche 2 tabelle di interesse sono la tabella dei fatti aggregata e la tabella di decodifica dei varchi.</p><p>E&rsquo; interessante che già in questa fase abbia dedotto che sia meglio fare la query sulla tabella aggregata rispetto a quella di dettaglio, ma mi stranisce un po&rsquo; il fatto che abbia fatto questa deduzione <strong>basandosi unicamente sulla naming della tabella</strong>, poiché l&rsquo;inferenza sui metadati e sui dati viene fatta solo in un momento successivo. In tal senso, il risultato finale potrebbe non essere quello corretto qualora le 2 tabelle avessero avuto un perimetro dati diverso (ad esempio qualora la tabella aggregata contenesse solo l&rsquo;ultimo anno).</p><p>Dopo aver letto i metadati e fatto un carotaggio dei dati, il LLM costruisce la query. In questo caso specifico si vede chiaramente che il modello indovina la sintassi della query al primo tentativo, ma ho sperimentato diversi casi in cui esso va a tentativi, correggendo di volta in volta la sintassi fino ad arrivare alla query definitiva (vedi casi B e C).</p><p>Il resto è autodescritto nell&rsquo;immagine.</p><p>Un paio di commenti:</p><ul><li>il modello è riuscito a implementare perfettamente i filtri che avevo in mente nel prompt, tramite inferenza sulla naming e/o sui dati</li><li>ho fatto altri tentativi rimuovendo la tabella aggregata e lasciando solo quella di dettaglio e ho ottenuto lo stesso risultato. Da notare però che la tabella di dettaglio ha il KPI in riga anziché in colonna, dunque in quel caso il modello ha capito che andava applicato il filtro &ldquo;des_tipo_alimentazione = &lsquo;diesel&rsquo;&rdquo;</li><li>come da attese, non è stata fatta alcuna ricerca su google, perché ovviamente non serviva</li></ul><h3 id=caso-b---informazioni-aggiuntive>Caso B - informazioni aggiuntive<a hidden class=anchor aria-hidden=true href=#caso-b---informazioni-aggiuntive>#</a></h3><blockquote><p><em>trova il varco in cui ci sono più transiti di veicoli diesel nel periodo di Agosto 2020, includendo solo ingressi areac ed escludendo i mezzi di servizio. Restituiscimi anche i 3 varchi più vicini ad esso</em></p></blockquote><p>Qui, il LLM mi ha sorpreso: ho aggiunto la frase finale per costringerlo a fare una ricerca su Google, ma non avevo pensato che partendo dalle coordinate geografiche fosse possibile calcolare la distanza con delle operazioni matematiche, dunque il tool (e cioè il modello LLM sottostante) ha eseguito l&rsquo;intero task all&rsquo;interno del DB tramite le funzioni <em>ST_POINT</em> ed <em>ST_DISTANCE</em> come mostrato in Figura 8.</p><p>Ho omesso la prima parte dell&rsquo;output perché identica al caso precedente.</p><figure><img loading=lazy src=/images/20230813/screenshot7_result_6.png><figcaption>Figura 4 - Output caso B</figcaption></figure><p>Come si vede dai vari messaggi di errore, in questo caso il modello ha avuto diverse &ldquo;allucinazioni&rdquo; nella costruzione della query SQL, ma è riuscito a correggerli fino ad arrivare alla query definitiva perché l&rsquo;agente ha restituito al modello LLM i feedback di tali errori tramite i loop <em>Action-Observation-Thought</em>.</p><h3 id=caso-c---esecuzione-combinata-sqlricerca>Caso C - esecuzione combinata SQL+Ricerca<a hidden class=anchor aria-hidden=true href=#caso-c---esecuzione-combinata-sqlricerca>#</a></h3><p>L&rsquo;estrema semplicità del modello dati non mi ha aiutato molto nel creare una richiesta sufficientemente articolata, dunque ho dovuto fare un po&rsquo; di prompt engineering per costringerlo a fare una ricerca sul web. Alla fine sono riuscito ad ottenere qualcosa con una richiesta di questo tipo:</p><blockquote><p><em>trova le coordinate e il nome descrittivo del varco in cui ci sono più transiti di veicoli diesel nel mese di Agosto 2020. Cerca la fermata dei mezzi pubblici più vicina a quel varco</em></p></blockquote><p>Qui sono accadute 2 cose strane:</p><ol><li>nonostante la prima parte del prompt fosse quasi identica al caso A (ho usato &ldquo;<em>nel mese di</em>&rdquo; anziché &ldquo;<em>nel periodo di</em>&rdquo;), il LLM esegue l&rsquo;operazione di MAX anziché di SUM</li><li>come da attese, l&rsquo;agente ha eseguito la ricerca tramite SerpApi per individuare la fermata dei mezzi ma, anziché usare le coordinate, ha usato il nome descrittivo del varco. Il risultato chiaramente non è in linea con le aspettative, perché viene restituita una fermata dei mezzi della città di Venezia</li></ol><figure><img loading=lazy src=/images/20230813/screenshot8_result_7.png><figcaption>Figura 4 - Output caso C</figcaption></figure><h2 id=conclusioni>Conclusioni<a hidden class=anchor aria-hidden=true href=#conclusioni>#</a></h2><p>Come già ho scritto nel precedente articolo, la curva di apprendimento per adottare LangChain è piuttosto bassa. Bastano poche righe di codice per ottenere un effetto &ldquo;wow&rdquo; e consentire a chiunque di implementare una propria soluzione custom, magari integrata con il resto dell&rsquo;ecosistema aziendale (repository documentali, Data APIs, mail server, shared file systems, &mldr;) e/o con il proprio LLM (ad esempio, è possibile integrare una propria installazione di Llama 2 on-premise) laddove non si vogliano condividere dati al di fuori dell&rsquo;organizzazione aziendale.</p><p>D&rsquo;altro canto, gli esempi che ho riportato sopra sono da considerarsi come tutorial semplificati per prendere dimestichezza con il framework.</p><p>Per mettere a terra delle soluzioni reali, serve un approccio più strutturato, che sfrutti meglio le caratteristiche del framework e tenga conto delle peculiarità dei modelli.</p><p>Ad esempio, mi sono reso conto che non è stata una scelta saggia quella di unire le funzionalità SQL e di ricerca SerpApi in un unico toolkit e che sarebbe stato meglio integrare le 2 funzionalità tramite agent/chain separati.</p><p>Come altro esempio, ho notato che nel pacchetto &ldquo;experimental&rdquo; è presente una classe che si chiama &ldquo;<em>SQLDatabaseChain</em>&rdquo; che con poche righe di codice permette di sviluppare un Tool Sql from scratch, bypassando completamente il toolkit standard:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sql_chain</span> <span class=o>=</span> <span class=n>SQLDatabaseChain</span><span class=o>.</span><span class=n>from_llm</span><span class=p>(</span><span class=n>llm</span><span class=o>=</span><span class=n>llm</span><span class=p>,</span> <span class=n>db</span><span class=o>=</span><span class=n>db</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sql_tool</span> <span class=o>=</span> <span class=n>Tool</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s1>&#39;Areac DB&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>func</span><span class=o>=</span><span class=n>sql_chain</span><span class=o>.</span><span class=n>run</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Database che contiene i dati relativi agli ingressi nei varchi dell&#39;area C di Milano.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; Le tabelle principali sono xtdpl1_ingressi_aggregated e xtdpl1_varchi.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; La tabella xtdpl1_ingressi_aggregated contiene le principali misure, come ad esempio il conteggio del numero di accessi per ciascuno dei varchi e per ciascun giorno dell&#39;anno.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; Il campo relativo alla dimensione tempo si chiama dat_year_month ed è di tipo numerico, nel classico formato YYYYMM.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; Il campo flg_areac è di tipo BOOLEAN (true/false) ed indica se si tratta di un ingresso effettivamente conteggiato come areac.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34; La tabella xtdpl1_varchi contiene la decodifica dei varchi. La chiave principale di questa tabella è il campo &#39;id&#39;, che identifica il varco. Gli altri attributi sono descrittivi.&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Poiché l&rsquo;agente utilizza il LLM per decidere QUALE tool utilizzare e COME utilizzarlo <strong>unicamente in base alla descrizione del tool</strong>, questo approccio ha il grande vantaggio di migliorare le performance semplicemente aggiungendo una descrizione efficace del DB all&rsquo;interno del tool, <strong>senza modificare in alcun modo il modello LLM</strong>.
Nel mio caso, ad esempio, ho aggiunto incrementalmente un gran numero di dettagli e ho notato un progressivo miglioramento delle performance.</p><section id=comments><script src=https://giscus.app/client.js data-repo=c-daniele/c-daniele.github.io data-repo-id=R_kgDOKIObxg data-category=Announcements data-category-id=DIC_kwDOKIObxs4Cu2th data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=it crossorigin=anonymous async></script></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://c-daniele.github.io/it/tags/ai/>ai</a></li><li><a href=https://c-daniele.github.io/it/tags/langchain/>langchain</a></li><li><a href=https://c-daniele.github.io/it/tags/agents/>agents</a></li></ul><nav class=paginav><a class=prev href=https://c-daniele.github.io/it/posts/2024-04-20-langchain-api/><span class=title>« Precedente</span><br><span>Langchain pt. 3 - Come invocare API Rest in linguaggio naturale</span></a>
<a class=next href=https://c-daniele.github.io/it/posts/2023-07-24-langchain-helloworld-pdf/><span class=title>Successivo »</span><br><span>LLM - Esperimenti con LangChain - Parte 1</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Langchain pt. 2 - Analisi dati tramite Agenti on twitter" href="https://twitter.com/intent/tweet/?text=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti&amp;url=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f&amp;hashtags=ai%2clangchain%2cagents"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Langchain pt. 2 - Analisi dati tramite Agenti on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f&amp;title=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti&amp;summary=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti&amp;source=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Langchain pt. 2 - Analisi dati tramite Agenti on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f&title=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Langchain pt. 2 - Analisi dati tramite Agenti on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Langchain pt. 2 - Analisi dati tramite Agenti on whatsapp" href="https://api.whatsapp.com/send?text=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti%20-%20https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Langchain pt. 2 - Analisi dati tramite Agenti on telegram" href="https://telegram.me/share/url?text=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti&amp;url=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Langchain pt. 2 - Analisi dati tramite Agenti on ycombinator" href="https://news.ycombinator.com/submitlink?t=Langchain%20pt.%202%20-%20Analisi%20dati%20tramite%20Agenti&u=https%3a%2f%2fc-daniele.github.io%2fit%2fposts%2f2023-08-13-langchain-agents%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://c-daniele.github.io/it/>Cdani's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copia";function s(){t.innerHTML="copiato!",setTimeout(()=>{t.innerHTML="copia"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>