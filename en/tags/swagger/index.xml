<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Swagger on Cdani&#39;s Blog</title>
    <link>https://c-daniele.github.io/en/tags/swagger/</link>
    <description>Recent content in Swagger on Cdani&#39;s Blog</description>
    <image>
      <title>Cdani&#39;s Blog</title>
      <url>https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Thu, 15 May 2025 00:00:00 +0200</lastBuildDate><atom:link href="https://c-daniele.github.io/en/tags/swagger/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Policy Puppetry Prompt Injection</title>
      <link>https://c-daniele.github.io/en/posts/2025-05-15-policy-puppetry/</link>
      <pubDate>Thu, 15 May 2025 00:00:00 +0200</pubDate>
      
      <guid>https://c-daniele.github.io/en/posts/2025-05-15-policy-puppetry/</guid>
      <description>Policy Puppetry Prompt Injection A few days ago, I experimented with some Jailbreaking techniques, which I share in the repo.
I started from a HiddenLayer article published a few weeks ago, where the research team described a rather creative and ingenious jailbreaking technique to bypass safety guardrails and the alignment of frontier models.
The technique appears to be universal and applicable with a single prompt to multiple models, capable of revealing typically unsafe content or even portions of the native system prompt.</description>
    </item>
    
    <item>
      <title>Langchain pt. 3 - How to call Rest API in natural language</title>
      <link>https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/</link>
      <pubDate>Sat, 20 Apr 2024 19:00:00 +0200</pubDate>
      
      <guid>https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/</guid>
      <description>Intro Last year, Gartner put Generative AI at the peak of inflated expectations in its AI Hype Cycle.
Recently, big tech leaders compared the hype around GenAI to the dotcom bubble. Furthermore, according to some rumors, the main Cloud Providers are even giving instructions to their Sales Teams to slow down the enthusiasm towards customers regarding GenAI initiatives and promoting cost-vs-benefits awareness. Has the drop into the trough of disillusionment already begun?</description>
    </item>
    
  </channel>
</rss>
