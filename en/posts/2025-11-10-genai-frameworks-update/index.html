<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Why LangChain Is Still the Best Framework for GenAI | Cdani's Blog</title><meta name=keywords content="GenAI,Langchain,Agents"><meta name=description content="Langchain 1.0 On October 22, 2025, LangChain finally reached version 1.0. After three years, this milestone represents something significantly different both from previous versions of the framework and from other competitors, which have become quite numerous in the meantime, creating some confusion and bewilderment for those who find themselves defining the software architecture for a new project.
To understand how volatile this market is, it&rsquo;s worth noting that the framework developed by Microsoft called &ldquo;AutoGen&rdquo;, with 51k+ GitHub stars, recently entered maintenance mode, as Microsoft decided to focus its efforts on the Microsoft Agent Framework, which is obviously much more integrated with Microsoft&rsquo;s GenAI services."><meta name=author content="Me"><link rel=canonical href=https://c-daniele.github.io/en/posts/2025-11-10-genai-frameworks-update/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.3598bbf45621a4ad34d093926efeb15d6df27175e085d2f069483f14ad39d7fa.css integrity="sha256-NZi79FYhpK000JOSbv6xXW3ycXXghdLwaUg/FK051/o=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://c-daniele.github.io/logo_cd_v3.svg><link rel=icon type=image/png sizes=16x16 href=https://c-daniele.github.io/logo_cd_v3.svg><link rel=icon type=image/png sizes=32x32 href=https://c-daniele.github.io/logo_cd_v3.svg><link rel=apple-touch-icon href=https://c-daniele.github.io/logo_cd_v3.svg><link rel=mask-icon href=https://c-daniele.github.io/logo_cd_v3.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=it href=https://c-daniele.github.io/it/posts/2025-11-10-genai-frameworks-update/><link rel=alternate hreflang=en href=https://c-daniele.github.io/en/posts/2025-11-10-genai-frameworks-update/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0,theme:"default",securityLevel:"loose"})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-8NZQZ3Z1RN"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8NZQZ3Z1RN",{anonymize_ip:!1})}</script><meta property="og:title" content="Why LangChain Is Still the Best Framework for GenAI"><meta property="og:description" content="Langchain 1.0 On October 22, 2025, LangChain finally reached version 1.0. After three years, this milestone represents something significantly different both from previous versions of the framework and from other competitors, which have become quite numerous in the meantime, creating some confusion and bewilderment for those who find themselves defining the software architecture for a new project.
To understand how volatile this market is, it&rsquo;s worth noting that the framework developed by Microsoft called &ldquo;AutoGen&rdquo;, with 51k+ GitHub stars, recently entered maintenance mode, as Microsoft decided to focus its efforts on the Microsoft Agent Framework, which is obviously much more integrated with Microsoft&rsquo;s GenAI services."><meta property="og:type" content="article"><meta property="og:url" content="https://c-daniele.github.io/en/posts/2025-11-10-genai-frameworks-update/"><meta property="og:image" content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-10T00:00:00+02:00"><meta property="article:modified_time" content="2025-11-10T00:00:00+02:00"><meta property="og:site_name" content="Cdani's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Why LangChain Is Still the Best Framework for GenAI"><meta name=twitter:description content="Langchain 1.0 On October 22, 2025, LangChain finally reached version 1.0. After three years, this milestone represents something significantly different both from previous versions of the framework and from other competitors, which have become quite numerous in the meantime, creating some confusion and bewilderment for those who find themselves defining the software architecture for a new project.
To understand how volatile this market is, it&rsquo;s worth noting that the framework developed by Microsoft called &ldquo;AutoGen&rdquo;, with 51k+ GitHub stars, recently entered maintenance mode, as Microsoft decided to focus its efforts on the Microsoft Agent Framework, which is obviously much more integrated with Microsoft&rsquo;s GenAI services."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":4,"name":"Why LangChain Is Still the Best Framework for GenAI","item":"https://c-daniele.github.io/en/posts/2025-11-10-genai-frameworks-update/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Why LangChain Is Still the Best Framework for GenAI","name":"Why LangChain Is Still the Best Framework for GenAI","description":"Langchain 1.0 On October 22, 2025, LangChain finally reached version 1.0. After three years, this milestone represents something significantly different both from previous versions of the framework and from other competitors, which have become quite numerous in the meantime, creating some confusion and bewilderment for those who find themselves defining the software architecture for a new project.\nTo understand how volatile this market is, it\u0026rsquo;s worth noting that the framework developed by Microsoft called \u0026ldquo;AutoGen\u0026rdquo;, with 51k+ GitHub stars, recently entered maintenance mode, as Microsoft decided to focus its efforts on the Microsoft Agent Framework, which is obviously much more integrated with Microsoft\u0026rsquo;s GenAI services.","keywords":["GenAI","Langchain","Agents"],"articleBody":"Langchain 1.0 On October 22, 2025, LangChain finally reached version 1.0. After three years, this milestone represents something significantly different both from previous versions of the framework and from other competitors, which have become quite numerous in the meantime, creating some confusion and bewilderment for those who find themselves defining the software architecture for a new project.\nTo understand how volatile this market is, it’s worth noting that the framework developed by Microsoft called “AutoGen”, with 51k+ GitHub stars, recently entered maintenance mode, as Microsoft decided to focus its efforts on the Microsoft Agent Framework, which is obviously much more integrated with Microsoft’s GenAI services.\nThe keyword now is “Agent”, and we witness the arrival of a new tool every week that promises to simplify AI agent development, but often these are wrappers that work very well in educational cases but, in an enterprise context, introduce more complexity than they solve.\nYet, LangChain 1.0 deserves attention for at least a couple of reasons:\nthe introduction of simple but effective tools (e.g., the concept of “middleware”) to facilitate the implementation of context engineering techniques, with the aim of optimizing the context window size and reducing token consumption the overall developer experience, which finally sees the main issues that plagued versions 0.x resolved. Problems Solved in LangChain 1.0 Area Issue (v0.x) Resolution (v1.0) Frequent Breaking Changes Frequent updates often introduced regressions, breaking existing code. Consequently, developers were often forced to remain on obsolete versions or fork to forcibly maintain backward compatibility. The Langchain team made an explicit commitment to the community: “no breaking changes until 2.0”, thus rigorous semantic versioning, clear deprecation notes with relative migration path, and separation of the langchain-classic package for backward compatibility with version 0.x constructs. Poor Documentation Outdated documentation, obsolete examples, fragmentation/inconsistency between Python/JavaScript versions. Completely redesigned docs site (docs.langchain.com), unified Python + JavaScript documentation with parallel examples, shared conceptual guides, consolidated API references, intuitive search and navigation tools. Excessive Abstractions Too heavy abstractions: developers had to navigate through numerous layers to model detailed processes and understand the behavior of unnecessary components, wasting time and energy Middleware system for fine-grained control, transparent design (no hidden prompts), built on LangGraph for low-level API access Token Usage Inefficiency There are documented cases of enormous inefficiency, up to 166% higher cost compared to a manual implementation, suboptimal batching, hidden API calls. Integrated structured output eliminates extra calls, optimized LangGraph runtime efficiency, explicit context management using middleware, automatic summarization. Dependency Bloat Even for small projects with few real dependencies (integrations, tools, vectordb, etc.) Langchain required the installation of an impressive number of dependencies, creating significant installation sizes and especially introducing potential vulnerabilities and conflicts. A cleaner and more rational package structure has been introduced, with langchain-core containing basic abstractions, standalone partner packages for each provider, and the langchain-classic package for backward compatibility. Lack of Type Safety Lack of a type-safety mechanism, especially in the case of tool or function call usage Type hints for content blocks, native Pydantic integration, explicit error handling. A Brief Overview of Some Major GenAI Frameworks One way to evaluate the impact of Langchain’s new features is to contextualize the discussion by examining the competitive landscape. In doing so, I limited myself to considering only four frameworks, each with distinct architectural approaches and philosophies. In my modest view, these are the most well-known and used, but obviously many other solutions exist, some of which might be better suited for specific use cases.\nLangChain: The Complete Ecosystem With 119,000 stars on GitHub, 19k+ forks and 1,500+ active contributors, LangChain unquestionably represents the most adopted framework in the sector. On the download front, we’re talking about more than 80 million monthly on PyPI and approximately 3.5 million on NPM, with growth of 220% on PyPI and 300% on NPM between Q1 2024 and Q1 2025.\nBut numbers alone say little. What distinguishes LangChain is the ecosystem created around the framework: it’s not simply a framework, but a complete platform that includes LangGraph for advanced orchestration, LangSmith for observability (arguably the most important element for the company’s business model), and over 600 pre-built integrations.\nLlamaIndex: The RAG Specialist LlamaIndex (44,000 stars, 4 million monthly downloads) opted for vertical specialization. Born as a framework focused on Retrieval Augmented Generation, it works very well in all use cases related to knowledge base management and document indexing. The AgentWorkflow architecture offers a simpler approach than LangChain for specific use cases, but this simplicity is also its limitation: when you move outside the pure RAG domain, the lack of enterprise functionality becomes evident.\nCrewAI: Simplified Agent Orchestration CrewAI (40,000 stars, 1.8 million monthly downloads) proposes a paradigm centered on Agent collaboration. The “Crews” abstraction is intuitive and the framework is indeed more accessible for developers approaching GenAI for the first time. However, this simplicity comes at a cost in terms of granular control: human-in-the-loop capabilities are basic, and the absence of an observability system comparable to LangSmith limits usage in real and complex production scenarios.\nHaystack: The Search Veteran Haystack (21,000 stars) represents a more traditional approach, with a rather rigid DAG pipeline architecture, although in version 2.0 they introduced various extensions and simplifications. It’s solid, reliable, but less flexible in orchestrating complex workflows. It doesn’t natively support human-in-the-loop, and its focus remains closer to semantic search than advanced agentic orchestration. It has about 80 integrations, a respectable number but far from LangChain’s coverage.\nHonorable Mention In addition to AutoGen, which we already mentioned, another honorable mention goes to Semantic Kernel (26k+ stars on github), the Microsoft-supported framework, which enjoys high adoption in enterprise environments but with a more limited integration ecosystem (about 25) and a significantly smaller community.\nThe Dimensions of Comparison 1. Agent Management Fundamental architectural differences emerge here. LangChain with LangGraph uses a state graph-based approach, where each node represents an operation and edges define conditional transitions. This architecture, although more complex initially, offers superior expressive power: robust state management, automatic checkpoints, ability to resume after crashes.\nLangChain 1.0’s new create_agent API represents a significant paradigm shift. Built on LangGraph’s battle-tested runtime, it allows creating production-ready agents in five lines of code while maintaining full power for streaming, error handling, and retry logic.\nCrewAI offers a more linear and intuitive model, where defining a team of agents is indeed more immediate. But when complex orchestration with conditional branches, loops, or sophisticated state management is needed, the architecture shows its limits.\nLlamaIndex positions itself in the middle with AgentWorkflow, an approach that balances explicitness and power, but remains inferior to LangGraph for complex multi-agent scenarios.\n2. Tool System and Integrations This is the point where, in my opinion, the gap is unbridgeable. LangChain offers 600+ pre-built integrations, from REST APIs to Slack, Notion, Google Drive, SQL databases, vector stores, cloud services. LlamaIndex has a moderate number, CrewAI reuses LangChain’s integrations, Haystack stops at about 80.\nIt’s not just a matter of numbers. Having native integrations means less boilerplate, fewer bugs, less time spent writing custom adapters.\n3. Memory and State Management Langchain recently introduced the concept of durable execution, through which execution state is automatically saved, allowing workflows that can last days, survive server restarts, and resume exactly from the interruption point using checkpoints.\nThis mechanism can be used to easily implement Human-in-the-loop patterns for execution pause and review, or time-travel debugging, through which it’s possible to go back and explore different actions.\nAmong other frameworks, CrewAI offers simpler but less powerful state management. Both LlamaIndex and Haystack manage state in a more explicit manner, thus delegating it to the developer. None of the competitors offer the combination of automatic persistence, time-travel debugging, and event streaming that LangGraph provides natively.\n4. LLM Integration and Multi-Provider Portability Here LangChain 1.0 introduces a very interesting feature: Content Blocks Standard API solving the problem of inconsistency in responses from different provider models. OpenAI returns one format, Anthropic another, Google Gemini yet another. This data format lock-in often forces developers to write provider-specific code.\nThe .content_blocks property provides a unified interface that works identically with OpenAI, Anthropic, Google Gemini, Azure, AWS Bedrock, Ollama, …. It supports text, reasoning traces, tool calls, web search, code execution, multimodal content.\nTo my knowledge, none of the other competitors have a comparable solution.\n5. Ease of Use and Learning Curve Despite the simplifications of version 1.0, criticisms of LangChain remain legitimate. The framework is not simple for beginners. The learning curve is steep, the layered architecture (LangChain Core → LangChain → LangGraph → LangSmith) can be disorienting, the documentation, although improved in v1.0, remains vast and sometimes fragmented.\nCrewAI and LlamaIndex are undoubtedly easier to use, at least for implementing simple use cases or prototypes. Even for a simple RAG or linear agent orchestration, these frameworks allow achieving good results in less time with less code.\nThe Innovation of the Middleware System It’s worth focusing on a feature that LangChain 1.0 introduces and that no competitor possesses: the middleware system. This is an example of architectural innovation that solves some problems elegantly.\nThe middleware provides fine-grained control over every step of the agent’s lifecycle without having to write low-level code. Middleware can be inserted for various purposes:\nHuman-in-the-loop: automatic pause of execution for approval or editing before critical actions Summarization: automatically compresses history when approaching token limits, optimizing costs PII Redaction: obscures sensitive information for GDPR/CCPA compliance Custom hook points allow intervention at specific points before_model, after_model, before_tool, after_tool, on_error, on_start, and on_end for total lifecycle control. This granularity eliminates the need for forking or monkey-patching, common patterns with other frameworks when custom behaviors are needed.\nLangChain’s Numbers The following numbers are certainly not indicative of technical quality, but they indicate momentum and market polarization. In a rapidly evolving ecosystem, being the framework that most developers are familiar with, for which more tutorials exist, more Stack Overflow answers, more case studies, more pre-built integrations, creates advantages even for standardization of the most basic skills.\n119,000 stars on GitHub (2.6x the closest competitor), with 19,627 forks and over 1,500 active contributors 76 million monthly downloads on PyPI (30x competitors), plus 3.5 million on NPM Download growth: 220% on PyPI and 300% on NPM between Q1 2024 and Q1 2025 1,300+ verified companies using LangChain in production (2025 data) 30,000+ active members on the Discord community 2,126 total job postings mentioning LangChain, of which 294 specific “LangChain Developer” positions with salary range $40-$105/hour $260M raised through 4 funding rounds: Seed (April 2023): $10M - Benchmark Capital Series A (February 2024): $25M - Sequoia Capital, $200M valuation Series B (July 2025): $100M - IVP, $1.1B valuation (unicorn status) Series C (October 2025): $125M - IVP, with new investors CapitalG (Google), Sapphire Ventures, and strategic from ServiceNow, Workday, Cisco, Datadog, Databricks Valuation growth: from $200M to $1.25 billion in 20 months (525% increase) LangSmith ARR: from $0 (launch February 2024) to $12-16M ARR in 18 months LangSmith: Native Observability An often underestimated aspect is observability. Langchain natively supports integration with LangSmith (just set an environment variable) and provides complete traces of every execution, granular cost tracking for token usage, latency breakdown for each chain step, integrated A/B testing, visual debugging of complex chains with time-travel capabilities.\nLangSmith’s growth is indicative: from $0 ARR at launch (February 2024) to $12-16 million ARR in just 18 months. This is not just a complementary product—it has become a differentiator for enterprise deployments.\nAll other competitors instead rely on third-party tools, sometimes mature, but which inevitably generate further fragmentation.\nWhen NOT to Use LangChain For intellectual honesty, it must be said: LangChain is not always the right choice.\nIf you’re prototyping a simple RAG bot for personal use, LlamaIndex is probably faster. If you want to orchestrate a team of agents with linear interactions without state complexity, CrewAI is more immediate. If you need optimal performance for a very specific use case, implementing from scratch might be more efficient.\nLangChain excels when:\nYou need complex multi-step orchestration You must integrate multiple data sources and tools You have significant requirements in terms of Compliance and audit trail You want to easily implement observability You want to avoid vendor lock-in at the LLM provider level The project will go into production and needs to scale If your use case doesn’t fall into these categories, evaluate simpler alternatives as the complexity might not be justified.\nConclusions: Maturity in an Immature Sector The GenAI sector suffers from a proliferation of tools reminiscent of the JavaScript framework explosion of the 2010s. Every week a new “game changer” emerges promising to revolutionize everything, but often replicates existing functionality with marginal variations.\nLangChain 1.0 truly represents a milestone: after the first troubled months, the company has learned from mistakes and the community has been heard, leading to a complete and mature architecture.\nReferences and Sources Official Documentation and Resources:\nLangChain Official Blog: https://blog.langchain.com LangChain Documentation: https://docs.langchain.com GitHub Repository: https://github.com/langchain-ai/langchain LangGraph Documentation: https://langchain-ai.github.io/langgraph/ Case Studies:\nLinkedIn SQL Bot - 85M+ active users Klarna Customer Support - 80% time reduction, 85M users Vodafone AI Chatbots - 340M+ customers Cisco Platform Engineer - 10x productivity boost Market Data and Surveys:\nStack Overflow Developer Survey 2025 - GenAI framework usage statistics JetBrains Developer Ecosystem Survey 2025 - Adoption trends Google DORA State of DevOps 2025 - Enterprise deployment patterns Financial Analysis:\nTechCrunch - Series C funding announcement Contrary Research - Valuation analysis and market positioning Metrics and Benchmarks:\nGitHub Stars \u0026 Contributors (November 2025 data) PyPI \u0026 NPM Download Statistics (monthly) Tonic Validate - Framework performance benchmarks ","wordCount":"2248","inLanguage":"en","datePublished":"2025-11-10T00:00:00+02:00","dateModified":"2025-11-10T00:00:00+02:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://c-daniele.github.io/en/posts/2025-11-10-genai-frameworks-update/"},"publisher":{"@type":"Organization","name":"Cdani's Blog","logo":{"@type":"ImageObject","url":"https://c-daniele.github.io/logo_cd_v3.svg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://c-daniele.github.io/en/ accesskey=h title="Home (Alt + H)"><img src=https://c-daniele.github.io/logo_cd_v3.svg alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://c-daniele.github.io/it/ title=Italiano aria-label=Italiano>It</a></li></ul></div></div><ul id=menu><li><a href=https://c-daniele.github.io/en/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://c-daniele.github.io/en/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://c-daniele.github.io/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://c-daniele.github.io/en/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://c-daniele.github.io/en/>Home</a></div><h1 class=post-title>Why LangChain Is Still the Best Framework for GenAI</h1><div class=post-meta><span title='2025-11-10 00:00:00 +0200 +0200'>November 10, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2248 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://c-daniele.github.io/it/posts/2025-11-10-genai-frameworks-update/>It</a></li></ul></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#problems-solved-in-langchain-10>Problems Solved in LangChain 1.0</a></li></ul><ul><li><a href=#langchain-the-complete-ecosystem>LangChain: The Complete Ecosystem</a></li><li><a href=#llamaindex-the-rag-specialist>LlamaIndex: The RAG Specialist</a></li><li><a href=#crewai-simplified-agent-orchestration>CrewAI: Simplified Agent Orchestration</a></li><li><a href=#haystack-the-search-veteran>Haystack: The Search Veteran</a></li><li><a href=#honorable-mention>Honorable Mention</a></li></ul><ul><li><a href=#1-agent-management>1. Agent Management</a></li><li><a href=#2-tool-system-and-integrations>2. Tool System and Integrations</a></li><li><a href=#3-memory-and-state-management>3. Memory and State Management</a></li><li><a href=#4-llm-integration-and-multi-provider-portability>4. LLM Integration and Multi-Provider Portability</a></li><li><a href=#5-ease-of-use-and-learning-curve>5. Ease of Use and Learning Curve</a></li></ul></nav></div></details></div><div class=post-content><h1 id=langchain-10>Langchain 1.0<a hidden class=anchor aria-hidden=true href=#langchain-10>#</a></h1><p>On October 22, 2025, <a href=https://blog.langchain.com>LangChain finally reached version 1.0</a>. After three years, this milestone represents something significantly different both from previous versions of the framework and from other competitors, which have become quite numerous in the meantime, creating some confusion and bewilderment for those who find themselves defining the software architecture for a new project.</p><p>To understand how volatile this market is, it&rsquo;s worth noting that the framework developed by Microsoft called &ldquo;<strong>AutoGen</strong>&rdquo;, with 51k+ GitHub stars, <strong>recently entered maintenance mode</strong>, as Microsoft decided to focus its efforts on the Microsoft Agent Framework, which is obviously much more integrated with Microsoft&rsquo;s GenAI services.</p><p>The keyword now is &ldquo;<strong>Agent</strong>&rdquo;, and we witness the arrival of a new tool every week that promises to simplify AI agent development, but often these are wrappers that work very well in educational cases but, in an enterprise context, introduce more complexity than they solve.</p><p>Yet, LangChain 1.0 deserves attention for at least a couple of reasons:</p><ul><li>the introduction of simple but effective tools (e.g., the concept of &ldquo;middleware&rdquo;) to facilitate the implementation of <strong>context engineering</strong> techniques, with the aim of optimizing the context window size and reducing token consumption</li><li>the <strong>overall developer experience</strong>, which finally sees the main issues that plagued versions 0.x resolved.</li></ul><h2 id=problems-solved-in-langchain-10>Problems Solved in LangChain 1.0<a hidden class=anchor aria-hidden=true href=#problems-solved-in-langchain-10>#</a></h2><table><thead><tr><th>Area</th><th>Issue (v0.x)</th><th>Resolution (v1.0)</th></tr></thead><tbody><tr><td><strong>Frequent Breaking Changes</strong></td><td>Frequent updates often introduced regressions, breaking existing code. Consequently, developers were often forced to remain on obsolete versions or fork to forcibly maintain backward compatibility.</td><td>The Langchain team made an explicit commitment to the community: &ldquo;no breaking changes until 2.0&rdquo;, thus rigorous semantic versioning, clear deprecation notes with relative migration path, and separation of the <code>langchain-classic</code> package for backward compatibility with version 0.x constructs.</td></tr><tr><td><strong>Poor Documentation</strong></td><td>Outdated documentation, obsolete examples, fragmentation/inconsistency between Python/JavaScript versions.</td><td>Completely redesigned docs site (docs.langchain.com), unified Python + JavaScript documentation with parallel examples, shared conceptual guides, consolidated API references, intuitive search and navigation tools.</td></tr><tr><td><strong>Excessive Abstractions</strong></td><td>Too heavy abstractions: developers had to navigate through numerous layers to model detailed processes and understand the behavior of unnecessary components, wasting time and energy</td><td>Middleware system for fine-grained control, transparent design (no hidden prompts), built on LangGraph for low-level API access</td></tr><tr><td><strong>Token Usage Inefficiency</strong></td><td>There are <a href=https://www.designveloper.com/blog/is-langchain-bad/>documented cases</a> of enormous inefficiency, up to 166% higher cost compared to a manual implementation, suboptimal batching, hidden API calls.</td><td>Integrated structured output eliminates extra calls, optimized LangGraph runtime efficiency, explicit context management using middleware, automatic summarization.</td></tr><tr><td><strong>Dependency Bloat</strong></td><td>Even for small projects with few real dependencies (integrations, tools, vectordb, etc.) Langchain required the installation of an impressive number of dependencies, creating significant installation sizes and especially introducing potential vulnerabilities and conflicts.</td><td>A cleaner and more rational package structure has been introduced, with <code>langchain-core</code> containing basic abstractions, standalone partner packages for each provider, and the <code>langchain-classic</code> package for backward compatibility.</td></tr><tr><td><strong>Lack of Type Safety</strong></td><td>Lack of a type-safety mechanism, especially in the case of tool or function call usage</td><td>Type hints for content blocks, native Pydantic integration, explicit error handling.</td></tr></tbody></table><h1 id=a-brief-overview-of-some-major-genai-frameworks>A Brief Overview of Some Major GenAI Frameworks<a hidden class=anchor aria-hidden=true href=#a-brief-overview-of-some-major-genai-frameworks>#</a></h1><p>One way to evaluate the impact of Langchain&rsquo;s new features is to contextualize the discussion by examining the competitive landscape. In doing so, I limited myself to considering only four frameworks, each with distinct architectural approaches and philosophies. In my modest view, these are the most well-known and used, but obviously many other solutions exist, some of which might be better suited for specific use cases.</p><h2 id=langchain-the-complete-ecosystem>LangChain: The Complete Ecosystem<a hidden class=anchor aria-hidden=true href=#langchain-the-complete-ecosystem>#</a></h2><p>With <a href=https://github.com/langchain-ai/langchain>119,000 stars on GitHub</a>, 19k+ forks and 1,500+ active contributors, LangChain unquestionably represents the most adopted framework in the sector. On the download front, we&rsquo;re talking about more than <a href=https://pypistats.org/packages/langchain>80 million monthly on PyPI</a> and approximately <a href=https://socket.dev/npm/package/langchain>3.5 million on NPM</a>, with growth of 220% on PyPI and 300% on NPM between Q1 2024 and Q1 2025.</p><p>But numbers alone say little. What distinguishes LangChain is the ecosystem created around the framework: it&rsquo;s not simply a framework, but a complete platform that includes LangGraph for advanced orchestration, LangSmith for observability (arguably the most important element for the company&rsquo;s business model), and over 600 pre-built integrations.</p><h2 id=llamaindex-the-rag-specialist>LlamaIndex: The RAG Specialist<a hidden class=anchor aria-hidden=true href=#llamaindex-the-rag-specialist>#</a></h2><p>LlamaIndex (44,000 stars, 4 million monthly downloads) opted for vertical specialization. Born as a framework focused on Retrieval Augmented Generation, it works very well in all use cases related to knowledge base management and document indexing. The AgentWorkflow architecture offers a simpler approach than LangChain for specific use cases, but this simplicity is also its limitation: when you move outside the pure RAG domain, the lack of enterprise functionality becomes evident.</p><h2 id=crewai-simplified-agent-orchestration>CrewAI: Simplified Agent Orchestration<a hidden class=anchor aria-hidden=true href=#crewai-simplified-agent-orchestration>#</a></h2><p>CrewAI (40,000 stars, 1.8 million monthly downloads) proposes a paradigm centered on Agent collaboration. The &ldquo;Crews&rdquo; abstraction is intuitive and the framework is indeed more accessible for developers approaching GenAI for the first time. However, this simplicity comes at a cost in terms of granular control: human-in-the-loop capabilities are basic, and the absence of an observability system comparable to LangSmith limits usage in real and complex production scenarios.</p><h2 id=haystack-the-search-veteran>Haystack: The Search Veteran<a hidden class=anchor aria-hidden=true href=#haystack-the-search-veteran>#</a></h2><p>Haystack (21,000 stars) represents a more traditional approach, with a rather rigid DAG pipeline architecture, although in version 2.0 they introduced various extensions and simplifications. It&rsquo;s solid, reliable, but less flexible in orchestrating complex workflows. It doesn&rsquo;t natively support human-in-the-loop, and its focus remains closer to semantic search than advanced agentic orchestration. It has about 80 integrations, a respectable number but far from LangChain&rsquo;s coverage.</p><h2 id=honorable-mention>Honorable Mention<a hidden class=anchor aria-hidden=true href=#honorable-mention>#</a></h2><p>In addition to AutoGen, which we already mentioned, another honorable mention goes to Semantic Kernel (26k+ stars on github), the Microsoft-supported framework, which enjoys high adoption in enterprise environments but with a more limited integration ecosystem (about 25) and a significantly smaller community.</p><h1 id=the-dimensions-of-comparison>The Dimensions of Comparison<a hidden class=anchor aria-hidden=true href=#the-dimensions-of-comparison>#</a></h1><h2 id=1-agent-management>1. Agent Management<a hidden class=anchor aria-hidden=true href=#1-agent-management>#</a></h2><p>Fundamental architectural differences emerge here. LangChain with <a href=https://langchain-ai.github.io/langgraph/>LangGraph</a> uses a state graph-based approach, where each node represents an operation and edges define conditional transitions. This architecture, although more complex initially, offers superior expressive power: robust state management, automatic checkpoints, ability to resume after crashes.</p><p>LangChain 1.0&rsquo;s new <code>create_agent</code> API represents a significant paradigm shift. Built on LangGraph&rsquo;s battle-tested runtime, it allows creating production-ready agents in five lines of code while maintaining full power for streaming, error handling, and retry logic.</p><p>CrewAI offers a more linear and intuitive model, where defining a team of agents is indeed more immediate. But when complex orchestration with conditional branches, loops, or sophisticated state management is needed, the architecture shows its limits.</p><p>LlamaIndex positions itself in the middle with AgentWorkflow, an approach that balances explicitness and power, but remains inferior to LangGraph for complex multi-agent scenarios.</p><h2 id=2-tool-system-and-integrations>2. Tool System and Integrations<a hidden class=anchor aria-hidden=true href=#2-tool-system-and-integrations>#</a></h2><p>This is the point where, in my opinion, the gap is unbridgeable. LangChain offers <strong>600+ pre-built integrations</strong>, from REST APIs to Slack, Notion, Google Drive, SQL databases, vector stores, cloud services. LlamaIndex has a moderate number, CrewAI reuses LangChain&rsquo;s integrations, Haystack stops at about 80.</p><p>It&rsquo;s not just a matter of numbers. Having native integrations means <strong>less boilerplate</strong>, fewer bugs, less time spent writing custom adapters.</p><h2 id=3-memory-and-state-management>3. Memory and State Management<a hidden class=anchor aria-hidden=true href=#3-memory-and-state-management>#</a></h2><p>Langchain recently introduced the concept of <strong>durable execution</strong>, through which execution state is automatically saved, allowing workflows that can last days, survive server restarts, and resume exactly from the interruption point using checkpoints.</p><p>This mechanism can be used to easily implement <strong>Human-in-the-loop</strong> patterns for execution pause and review, or <strong>time-travel</strong> debugging, through which it&rsquo;s possible to go back and explore different actions.</p><p>Among other frameworks, CrewAI offers simpler but less powerful state management. Both LlamaIndex and Haystack manage state in a more explicit manner, thus delegating it to the developer. None of the competitors offer the combination of automatic persistence, time-travel debugging, and event streaming that LangGraph provides natively.</p><h2 id=4-llm-integration-and-multi-provider-portability>4. LLM Integration and Multi-Provider Portability<a hidden class=anchor aria-hidden=true href=#4-llm-integration-and-multi-provider-portability>#</a></h2><p>Here LangChain 1.0 introduces a very interesting feature: <strong>Content Blocks Standard API</strong> solving the problem of inconsistency in responses from different provider models. OpenAI returns one format, Anthropic another, Google Gemini yet another. This data format lock-in often forces developers to write provider-specific code.</p><p>The <code>.content_blocks</code> property provides a unified interface that works identically with OpenAI, Anthropic, Google Gemini, Azure, AWS Bedrock, Ollama, &mldr;. It supports text, reasoning traces, tool calls, web search, code execution, multimodal content.</p><p>To my knowledge, none of the other competitors have a comparable solution.</p><h2 id=5-ease-of-use-and-learning-curve>5. Ease of Use and Learning Curve<a hidden class=anchor aria-hidden=true href=#5-ease-of-use-and-learning-curve>#</a></h2><p>Despite the simplifications of version 1.0, criticisms of LangChain remain legitimate. The framework is not simple for beginners. The learning curve is steep, the layered architecture (LangChain Core → LangChain → LangGraph → LangSmith) can be disorienting, the documentation, although improved in v1.0, remains vast and sometimes fragmented.</p><p>CrewAI and LlamaIndex are undoubtedly easier to use, at least for implementing simple use cases or prototypes. Even for a simple RAG or linear agent orchestration, these frameworks allow achieving good results in less time with less code.</p><h1 id=the-innovation-of-the-middleware-system>The Innovation of the Middleware System<a hidden class=anchor aria-hidden=true href=#the-innovation-of-the-middleware-system>#</a></h1><p>It&rsquo;s worth focusing on a feature that LangChain 1.0 introduces and that no competitor possesses: the <strong>middleware</strong> system. This is an example of architectural innovation that solves some problems elegantly.</p><p>The middleware provides fine-grained control over every step of the agent&rsquo;s lifecycle without having to write low-level code. Middleware can be inserted for various purposes:</p><ul><li><strong>Human-in-the-loop</strong>: automatic pause of execution for approval or editing before critical actions</li><li><strong>Summarization</strong>: automatically compresses history when approaching token limits, optimizing costs</li><li><strong>PII Redaction</strong>: obscures sensitive information for GDPR/CCPA compliance</li></ul><p>Custom hook points allow intervention at specific points <code>before_model</code>, <code>after_model</code>, <code>before_tool</code>, <code>after_tool</code>, <code>on_error</code>, <code>on_start</code>, and <code>on_end</code> for total lifecycle control. This granularity eliminates the need for forking or monkey-patching, common patterns with other frameworks when custom behaviors are needed.</p><h1 id=langchains-numbers>LangChain&rsquo;s Numbers<a hidden class=anchor aria-hidden=true href=#langchains-numbers>#</a></h1><p>The following numbers are certainly not indicative of technical quality, but they indicate momentum and market polarization. In a rapidly evolving ecosystem, being the framework that most developers are familiar with, for which more tutorials exist, more Stack Overflow answers, more case studies, more pre-built integrations, creates advantages even for standardization of the most basic skills.</p><ul><li><strong>119,000 stars on GitHub</strong> (2.6x the closest competitor), with 19,627 forks and over 1,500 active contributors</li><li><strong>76 million monthly downloads on PyPI</strong> (30x competitors), plus 3.5 million on NPM</li><li><strong>Download growth</strong>: 220% on PyPI and 300% on NPM between Q1 2024 and Q1 2025</li><li><strong>1,300+ verified companies</strong> using LangChain in production (<a href=https://data.landbase.com/technology/langchain/>2025 data</a>)</li><li><strong>30,000+ active members</strong> on the Discord community</li><li><strong>2,126 total job postings</strong> mentioning LangChain, of which 294 specific &ldquo;LangChain Developer&rdquo; positions with salary range <strong>$40-$105/hour</strong></li><li><strong>$260M raised</strong> through 4 funding rounds:<ul><li>Seed (April 2023): $10M - Benchmark Capital</li><li>Series A (February 2024): $25M - Sequoia Capital, $200M valuation</li><li>Series B (July 2025): $100M - IVP, $1.1B valuation (unicorn status)</li><li>Series C (October 2025): $125M - IVP, with new investors CapitalG (Google), Sapphire Ventures, and strategic from ServiceNow, Workday, Cisco, Datadog, Databricks</li></ul></li><li><strong>Valuation growth</strong>: from $200M to $1.25 billion in 20 months (<strong>525% increase</strong>)</li><li><strong>LangSmith ARR</strong>: from $0 (launch February 2024) to $12-16M ARR in 18 months</li></ul><h1 id=langsmith-native-observability>LangSmith: Native Observability<a hidden class=anchor aria-hidden=true href=#langsmith-native-observability>#</a></h1><p>An often underestimated aspect is observability. Langchain natively supports integration with LangSmith (just set an environment variable) and provides complete traces of every execution, granular cost tracking for token usage, latency breakdown for each chain step, integrated A/B testing, visual debugging of complex chains with time-travel capabilities.</p><p>LangSmith&rsquo;s growth is indicative: from $0 ARR at launch (February 2024) to <a href=https://techcrunch.com/2025/07/08/langchain-is-about-to-become-a-unicorn-sources-say/>$12-16 million ARR in just 18 months</a>. This is not just a complementary product—it has become a differentiator for enterprise deployments.</p><p>All other competitors instead rely on third-party tools, sometimes mature, but which inevitably generate further fragmentation.</p><h1 id=when-not-to-use-langchain>When NOT to Use LangChain<a hidden class=anchor aria-hidden=true href=#when-not-to-use-langchain>#</a></h1><p>For intellectual honesty, it must be said: LangChain is not always the right choice.</p><p>If you&rsquo;re prototyping a simple RAG bot for personal use, LlamaIndex is probably faster. If you want to orchestrate a team of agents with linear interactions without state complexity, CrewAI is more immediate. If you need optimal performance for a very specific use case, implementing from scratch might be more efficient.</p><p>LangChain excels when:</p><ul><li>You need complex multi-step orchestration</li><li>You must integrate multiple data sources and tools</li><li>You have significant requirements in terms of Compliance and audit trail</li><li>You want to easily implement observability</li><li>You want to avoid vendor lock-in at the LLM provider level</li><li>The project will go into production and needs to scale</li></ul><p>If your use case doesn&rsquo;t fall into these categories, evaluate simpler alternatives as the complexity might not be justified.</p><h1 id=conclusions-maturity-in-an-immature-sector>Conclusions: Maturity in an Immature Sector<a hidden class=anchor aria-hidden=true href=#conclusions-maturity-in-an-immature-sector>#</a></h1><p>The GenAI sector suffers from a proliferation of tools reminiscent of the JavaScript framework explosion of the 2010s. Every week a new &ldquo;game changer&rdquo; emerges promising to revolutionize everything, but often replicates existing functionality with marginal variations.</p><p>LangChain 1.0 truly represents a milestone: after the first troubled months, the company has learned from mistakes and the community has been heard, leading to a complete and mature architecture.</p><hr><h1 id=references-and-sources>References and Sources<a hidden class=anchor aria-hidden=true href=#references-and-sources>#</a></h1><p><strong>Official Documentation and Resources:</strong></p><ul><li>LangChain Official Blog: <a href=https://blog.langchain.com>https://blog.langchain.com</a></li><li>LangChain Documentation: <a href=https://docs.langchain.com>https://docs.langchain.com</a></li><li>GitHub Repository: <a href=https://github.com/langchain-ai/langchain>https://github.com/langchain-ai/langchain</a></li><li>LangGraph Documentation: <a href=https://langchain-ai.github.io/langgraph/>https://langchain-ai.github.io/langgraph/</a></li></ul><p><strong>Case Studies:</strong></p><ul><li><a href=https://blog.langchain.com/case-study-linkedin/>LinkedIn SQL Bot</a> - 85M+ active users</li><li><a href=https://blog.langchain.com/case-study-klarna/>Klarna Customer Support</a> - 80% time reduction, 85M users</li><li><a href=https://blog.langchain.com/case-study-vodafone/>Vodafone AI Chatbots</a> - 340M+ customers</li><li><a href=https://blog.langchain.com/case-study-cisco/>Cisco Platform Engineer</a> - 10x productivity boost</li></ul><p><strong>Market Data and Surveys:</strong></p><ul><li>Stack Overflow Developer Survey 2025 - GenAI framework usage statistics</li><li>JetBrains Developer Ecosystem Survey 2025 - Adoption trends</li><li>Google DORA State of DevOps 2025 - Enterprise deployment patterns</li></ul><p><strong>Financial Analysis:</strong></p><ul><li>TechCrunch - Series C funding announcement</li><li>Contrary Research - Valuation analysis and market positioning</li></ul><p><strong>Metrics and Benchmarks:</strong></p><ul><li>GitHub Stars & Contributors (November 2025 data)</li><li>PyPI & NPM Download Statistics (monthly)</li><li>Tonic Validate - Framework performance benchmarks</li></ul><section id=comments><script src=https://giscus.app/client.js data-repo=c-daniele/c-daniele.github.io data-repo-id=R_kgDOKIObxg data-category=Announcements data-category-id=DIC_kwDOKIObxs4Cu2th data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=it crossorigin=anonymous async></script></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://c-daniele.github.io/en/tags/genai/>GenAI</a></li><li><a href=https://c-daniele.github.io/en/tags/langchain/>Langchain</a></li><li><a href=https://c-daniele.github.io/en/tags/agents/>Agents</a></li></ul><nav class=paginav><a class=prev href=https://c-daniele.github.io/en/posts/2026-02-14-intro-spec-driven-development/><span class=title>« Prev</span><br><span>The Developer --> Designer switch</span></a>
<a class=next href=https://c-daniele.github.io/en/posts/2025-10-11-bells-inequalities/><span class=title>Next »</span><br><span>Bell's Inequalities: A quantum computing experiment with Qiskit</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Why LangChain Is Still the Best Framework for GenAI on twitter" href="https://twitter.com/intent/tweet/?text=Why%20LangChain%20Is%20Still%20the%20Best%20Framework%20for%20GenAI&amp;url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f&amp;hashtags=GenAI%2cLangchain%2cAgents"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Why LangChain Is Still the Best Framework for GenAI on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f&amp;title=Why%20LangChain%20Is%20Still%20the%20Best%20Framework%20for%20GenAI&amp;summary=Why%20LangChain%20Is%20Still%20the%20Best%20Framework%20for%20GenAI&amp;source=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Why LangChain Is Still the Best Framework for GenAI on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f&title=Why%20LangChain%20Is%20Still%20the%20Best%20Framework%20for%20GenAI"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Why LangChain Is Still the Best Framework for GenAI on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Why LangChain Is Still the Best Framework for GenAI on whatsapp" href="https://api.whatsapp.com/send?text=Why%20LangChain%20Is%20Still%20the%20Best%20Framework%20for%20GenAI%20-%20https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Why LangChain Is Still the Best Framework for GenAI on telegram" href="https://telegram.me/share/url?text=Why%20LangChain%20Is%20Still%20the%20Best%20Framework%20for%20GenAI&amp;url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Why LangChain Is Still the Best Framework for GenAI on ycombinator" href="https://news.ycombinator.com/submitlink?t=Why%20LangChain%20Is%20Still%20the%20Best%20Framework%20for%20GenAI&u=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2025-11-10-genai-frameworks-update%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://c-daniele.github.io/en/>Cdani's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>