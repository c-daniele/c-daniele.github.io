<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LLM - Experimenting LangChain - Part 1 | Cdani's Blog</title><meta name=keywords content="ai,langchain"><meta name=description content="Intro For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.
As the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:
Prompt Templates: they refer to a reproducible way to generate a prompt. Contains a text string (&ldquo;the model&rdquo;), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model The language model (LLM): LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc) Output Parsers: allow to extract structure data form from the answers returned by the linguistic model The framework has 2 very interesting features:"><meta name=author content="Me"><link rel=canonical href=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.3598bbf45621a4ad34d093926efeb15d6df27175e085d2f069483f14ad39d7fa.css integrity="sha256-NZi79FYhpK000JOSbv6xXW3ycXXghdLwaUg/FK051/o=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=it href=https://c-daniele.github.io/it/posts/2023-07-24-langchain-helloworld-pdf/><link rel=alternate hreflang=en href=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-8NZQZ3Z1RN"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8NZQZ3Z1RN",{anonymize_ip:!1})}</script><meta property="og:title" content="LLM - Experimenting LangChain - Part 1"><meta property="og:description" content="Intro For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.
As the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:
Prompt Templates: they refer to a reproducible way to generate a prompt. Contains a text string (&ldquo;the model&rdquo;), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model The language model (LLM): LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc) Output Parsers: allow to extract structure data form from the answers returned by the linguistic model The framework has 2 very interesting features:"><meta property="og:type" content="article"><meta property="og:url" content="https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/"><meta property="og:image" content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-24T17:14:03+02:00"><meta property="article:modified_time" content="2023-07-24T17:45:02+02:00"><meta property="og:site_name" content="Cdani's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="LLM - Experimenting LangChain - Part 1"><meta name=twitter:description content="Intro For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.
As the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:
Prompt Templates: they refer to a reproducible way to generate a prompt. Contains a text string (&ldquo;the model&rdquo;), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model The language model (LLM): LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc) Output Parsers: allow to extract structure data form from the answers returned by the linguistic model The framework has 2 very interesting features:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":4,"name":"LLM - Experimenting LangChain - Part 1","item":"https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LLM - Experimenting LangChain - Part 1","name":"LLM - Experimenting LangChain - Part 1","description":"Intro For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.\nAs the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:\nPrompt Templates: they refer to a reproducible way to generate a prompt. Contains a text string (\u0026ldquo;the model\u0026rdquo;), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model The language model (LLM): LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc) Output Parsers: allow to extract structure data form from the answers returned by the linguistic model The framework has 2 very interesting features:","keywords":["ai","langchain"],"articleBody":"Intro For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.\nAs the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:\nPrompt Templates: they refer to a reproducible way to generate a prompt. Contains a text string (“the model”), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model The language model (LLM): LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc) Output Parsers: allow to extract structure data form from the answers returned by the linguistic model The framework has 2 very interesting features:\nit can extend LLM knowledge with your own database, leveragine structured and unstructured datasets it provides the “Agent” capabilities by which the action itself is an output returned from the LLM I was quite curious about the first item, so I’ve started making some tests. I don’t want to make a critical analysis of the model performance, but rather verify how easy is to integrate the framework into one’s own database.\nIntegration with unstructured data I didn’t know where to start, so I took a look at the most documented use cases on the internet. I’ve found a lot of documentation related to parsing PDF files, so it seemed like an area I could experiment with a lot.\nIn the official documentation there’s a special section related to the “Data Connection”, which I found incredibly clear and intuitive. I will try to summarize here the most important points.\nThe building blocks made available by LangChain are the following:\nDocument: it’s an abstraction containing both the data in textual form and the associated metadata Document loaders: They are classes that allow you to extract text and metadata from a specific type of data in order to build the “Document” Document transformers: it’s used to process Documents. Since LLMs usually have strong limitations in terms of available tokens, the most common transformation is related to chunk splitting, through which it is possible to submit calls to the LLM provider in series or in parallel. There are also other types of transformers, for example: redundancy reduction, translation, metadata extraction, etc… Text embedding: it’s the operation of translating a portion of text into an N-dimensional vector model, which is the core component for the semantic search operations based on similarity indexes and implemented by calculating vector distances across such N-dimensional space Vector stores: it stores the embeddings inside a vector DB Engine, which is capable of efficiently returning the vectors closest to the input text (and therefore the portions of text that are most similar). It’s possible to exploit some open source DB engines to run everything locally, or to integrate with some market products that obviously offer much better performance (eg: Pinecone) Retrievers: it’s an interface that returns documents from an unstructured query. It is a slightly more general concept than a Vector Store, but unlike the latter, it only allows you to return documents and not necessarily store them Chains So let’s talk about the main components: the chains.\nLangChain introduces this concept which represents a useful abstraction to implement applications that make use of LLMs in a simple and modular way. There are many predefined Chains, the most common are:\nRetrievalQA: it responds to user input from the output returned by a retriever ConversationalRetrievalChain: it’s similar to RetrievalQA. It adds the capability to build a conversational experience through the history of exchanged messages Summarize: as the name suggests, it enable text summarization The experiment I took a 2017 research paper, written by some researchers at the Oak Ridge National Laboratory (ORNL) and other university institutes, which proposes an implementation of a quantum computing algorithm for a Portfolio Optimization problem.\nIn particular, the article describes the advantages deriving from the use of a variant of the Markowitz model (QUBO) on D-Wave type quantum devices.\nThe complete article can be found at this link.\nBeing passionate about these topics, but not having a solid theoretical basis, I can understand the main points of the paper, but I have no competence to evaluate the reliability or the goodness of the results, so I decide to ask OpenAI for a critical analysis, passing through LangChain.\nSurprisingly, it only took me a few hours and less than 20 lines of code to get a working prototype with an overall good result.\nThe code Here you can find the source code. It’s almost self-describing, but I’m adding some further notes and comments below.\nfrom langchain.llms import OpenAI from langchain.document_loaders import PyPDFLoader from langchain.chains.summarize import load_summarize_chain from langchain import OpenAI, PromptTemplate from dotenv import load_dotenv load_dotenv() loader = PyPDFLoader(\"docs/pdf/102.pdf\") docs = [] docs.extend(loader.load()) prompt_template = \"\"\"Write a negative critique of this research article, questioning its findings and applicability: {text} CRITICS:\"\"\" PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"]) chain = load_summarize_chain(OpenAI(temperature=0.5), chain_type=\"map_reduce\", return_intermediate_steps=False, map_prompt=PROMPT, combine_prompt=PROMPT) chain({\"input_documents\": docs}, return_only_outputs=True) The call to load_dotenv() is for loading the OPENAI_API_KEY environment variable, associated with my OpenAI account. The first instructions are used to initialize the loader and create the associated “Documents”. Right after that, I define the prompt template and call the “Summarize” chain. The first parameter passed to the Chain is an OpenAI-type LLM instantiation, which I deliberately configured with a temperature of 0.5, to push the creativity a little bit. The chain_type is “map_reduce” because the text is long enough to exceed the 4096 token limit imposed by the provider I’m using (ChatGPT 3.5).\nOutcomes Please find below a couple of outcomes I got from the above code:\nThis research article presents a variety of methodologies for analyzing portfolio selection in the presence of multiple criteria. However, the results are based on mathematical theories and simulation models rather than real data. Also, using a fixed $100 budget is unrealistic and does not represent real-world conditions. Furthermore, most of the techniques described in this article are not applicable to real financial markets, as they do not take into account factors such as market volatility, economic cycles, etc. Consequently, the findings and applicability of this research article are questioned.\nThis research article does not provide sufficient evidence of the results obtained, nor does it demonstrate the applicability of the proposed model in practice. Markowitz’s theory of portfolio selection is not applicable to all investors, as it does not consider the complications that can arise in practice, such as taxes or fees. Also, the use of the D-Wave quantum optimizer has not been adequately demonstrated. The relaxed wording does not involve buying shares, which means that the optimal outcome is not realistic. Also, the abundance of zeros in the data is unrealistic. Most of the sample code and applications mentioned in the article are computation related\nConclusions As I said earlier, I can’t claim any strong subject mastership for evaluate if the outcome i got from the LLM have solid foundations or not, but at first sight they seem to be realistic and strong enough to suggest some thoughts.\nFor example, if we take the comment about the investment of only $100, this is actually a simplified scenario they considered in the paper, but to be honest I have no idea if this factor can effectively question the results.\nIn general, the thing that amazed me is the ease with which the framework makes the building blocks available for developing AI applications, without reinventing the wheel and integrating very well with the main providers and market products.\nI realize the example shown is really trivial, but it opens up a world of possibilities. I’m doing other tests by expanding the dataset and trying to answer slightly more complex questions. Stay tuned\n","wordCount":"1281","inLanguage":"en","datePublished":"2023-07-24T17:14:03+02:00","dateModified":"2023-07-24T17:45:02+02:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/"},"publisher":{"@type":"Organization","name":"Cdani's Blog","logo":{"@type":"ImageObject","url":"https://c-daniele.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://c-daniele.github.io/en/ accesskey=h title="Home (Alt + H)"><img src=https://c-daniele.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://c-daniele.github.io/it/ title=Italiano aria-label=Italiano>It</a></li></ul></div></div><ul id=menu><li><a href=https://c-daniele.github.io/en/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://c-daniele.github.io/en/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://c-daniele.github.io/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://c-daniele.github.io/en/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://c-daniele.github.io/en/>Home</a></div><h1 class=post-title>LLM - Experimenting LangChain - Part 1</h1><div class=post-meta><span title='2023-07-24 17:45:02 +0200 +0200'>July 24, 2023</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1281 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://c-daniele.github.io/it/posts/2023-07-24-langchain-helloworld-pdf/>It</a></li></ul></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#integration-with-unstructured-data>Integration with unstructured data</a></li><li><a href=#chains>Chains</a></li><li><a href=#the-experiment>The experiment</a><ul><li><a href=#the-code>The code</a></li><li><a href=#outcomes>Outcomes</a></li></ul></li><li><a href=#conclusions>Conclusions</a></li></ul></nav></div></details></div><div class=post-content><h2 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h2><p>For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.</p><p>As the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:</p><ul><li><strong>Prompt Templates</strong>: they refer to a reproducible way to generate a prompt. Contains a text string (&ldquo;the model&rdquo;), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model</li><li>The <strong>language model (LLM)</strong>: LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc)</li><li><strong>Output Parsers</strong>: allow to extract structure data form from the answers returned by the linguistic model</li></ul><hr><p>The framework has 2 very interesting features:</p><ol><li>it can extend LLM knowledge with <strong>your own database</strong>, leveragine structured and unstructured datasets</li><li>it provides the &ldquo;<strong>Agent</strong>&rdquo; capabilities by which the action itself is an output returned from the LLM</li></ol><p>I was quite curious about the first item, so I&rsquo;ve started making some tests. I don&rsquo;t want to make a critical analysis of the model performance, but rather verify how easy is to integrate the framework into one&rsquo;s own database.</p><h2 id=integration-with-unstructured-data>Integration with unstructured data<a hidden class=anchor aria-hidden=true href=#integration-with-unstructured-data>#</a></h2><p>I didn&rsquo;t know where to start, so I took a look at the most documented use cases on the internet. I&rsquo;ve found a lot of documentation related to parsing PDF files, so it seemed like an area I could experiment with a lot.</p><p>In the official documentation there&rsquo;s a special section related to the &ldquo;<em>Data Connection</em>&rdquo;, which I found incredibly clear and intuitive. I will try to summarize here the most important points.</p><p>The building blocks made available by LangChain are the following:</p><ul><li><strong>Document</strong>: it&rsquo;s an abstraction containing both the data in textual form and the associated metadata</li><li><strong>Document loaders</strong>: They are classes that allow you to extract text and metadata from a specific type of data in order to build the &ldquo;Document&rdquo;</li><li><strong>Document transformers</strong>: it&rsquo;s used to process Documents. Since LLMs usually have strong limitations in terms of available tokens, the most common transformation is related to chunk splitting, through which it is possible to submit calls to the LLM provider in series or in parallel. There are also other types of transformers, for example: redundancy reduction, translation, metadata extraction, etc&mldr;</li><li><strong>Text embedding</strong>: it&rsquo;s the operation of translating a portion of text into an N-dimensional vector model, which is the core component for the semantic search operations based on similarity indexes and implemented by calculating vector distances across such N-dimensional space</li><li><strong>Vector stores</strong>: it stores the embeddings inside a vector DB Engine, which is capable of efficiently returning the vectors closest to the input text (and therefore the portions of text that are most similar). It&rsquo;s possible to exploit some open source DB engines to run everything locally, or to integrate with some market products that obviously offer much better performance (eg: Pinecone)</li><li><strong>Retrievers</strong>: it&rsquo;s an interface that returns documents from an unstructured query. It is a slightly more general concept than a Vector Store, but unlike the latter, it only allows you to return documents and not necessarily store them</li></ul><h2 id=chains>Chains<a hidden class=anchor aria-hidden=true href=#chains>#</a></h2><p>So let&rsquo;s talk about the main components: the <strong>chains</strong>.</p><p>LangChain introduces this concept which represents a useful abstraction to implement applications that make use of LLMs in a simple and modular way.
There are many predefined Chains, the most common are:</p><ul><li><strong>RetrievalQA</strong>: it responds to user input from the output returned by a retriever</li><li><strong>ConversationalRetrievalChain</strong>: it&rsquo;s similar to RetrievalQA. It adds the capability to build a conversational experience through the history of exchanged messages</li><li><strong>Summarize</strong>: as the name suggests, it enable text summarization</li></ul><h2 id=the-experiment>The experiment<a hidden class=anchor aria-hidden=true href=#the-experiment>#</a></h2><p>I took a 2017 research paper, written by some researchers at the Oak Ridge National Laboratory (ORNL) and other university institutes, which proposes an implementation of a quantum computing algorithm for a Portfolio Optimization problem.</p><p>In particular, the article describes the advantages deriving from the use of a variant of the Markowitz model (QUBO) on D-Wave type quantum devices.</p><p>The complete article can be found at <a href=https://ieee-hpec.org/2017/techprog2017/index_htm_files/102.pdf>this link</a>.</p><p>Being passionate about these topics, but not having a solid theoretical basis, I can understand the main points of the paper, but I have no competence to evaluate the reliability or the goodness of the results, so I decide to ask OpenAI for a critical analysis, passing through LangChain.</p><p>Surprisingly, it only took me a few hours and <strong>less than 20 lines of code</strong> to get a working prototype with an overall good result.</p><h3 id=the-code>The code<a hidden class=anchor aria-hidden=true href=#the-code>#</a></h3><p>Here you can find the source code. It&rsquo;s almost self-describing, but I&rsquo;m adding some further notes and comments below.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.llms</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.document_loaders</span> <span class=kn>import</span> <span class=n>PyPDFLoader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains.summarize</span> <span class=kn>import</span> <span class=n>load_summarize_chain</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain</span> <span class=kn>import</span> <span class=n>OpenAI</span><span class=p>,</span> <span class=n>PromptTemplate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>loader</span> <span class=o>=</span> <span class=n>PyPDFLoader</span><span class=p>(</span><span class=s2>&#34;docs/pdf/102.pdf&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>docs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>docs</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>loader</span><span class=o>.</span><span class=n>load</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt_template</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;Write a negative critique of this research article, questioning its findings and applicability:
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2></span><span class=si>{text}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>CRITICS:&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=n>PROMPT</span> <span class=o>=</span> <span class=n>PromptTemplate</span><span class=p>(</span><span class=n>template</span><span class=o>=</span><span class=n>prompt_template</span><span class=p>,</span> <span class=n>input_variables</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;text&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>chain</span> <span class=o>=</span> <span class=n>load_summarize_chain</span><span class=p>(</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span> <span class=n>chain_type</span><span class=o>=</span><span class=s2>&#34;map_reduce&#34;</span><span class=p>,</span> <span class=n>return_intermediate_steps</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>map_prompt</span><span class=o>=</span><span class=n>PROMPT</span><span class=p>,</span> <span class=n>combine_prompt</span><span class=o>=</span><span class=n>PROMPT</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>chain</span><span class=p>({</span><span class=s2>&#34;input_documents&#34;</span><span class=p>:</span> <span class=n>docs</span><span class=p>},</span> <span class=n>return_only_outputs</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></div><p>The call to <code>load_dotenv()</code> is for loading the <em>OPENAI_API_KEY</em> environment variable, associated with my OpenAI account.
The first instructions are used to initialize the loader and create the associated &ldquo;Documents&rdquo;. Right after that, I define the prompt template and call the &ldquo;Summarize&rdquo; chain.
The first parameter passed to the Chain is an OpenAI-type LLM instantiation, which I deliberately configured with a temperature of 0.5, to push the creativity a little bit. The chain_type is &ldquo;<em>map_reduce</em>&rdquo; because the text is long enough to exceed the 4096 token limit imposed by the provider I&rsquo;m using (ChatGPT 3.5).</p><h3 id=outcomes>Outcomes<a hidden class=anchor aria-hidden=true href=#outcomes>#</a></h3><p>Please find below a couple of outcomes I got from the above code:</p><blockquote><p>This research article presents a variety of methodologies for analyzing portfolio selection in the presence of multiple criteria. However, the results are based on mathematical theories and simulation models rather than real data. Also, using a fixed $100 budget is unrealistic and does not represent real-world conditions. Furthermore, most of the techniques described in this article are not applicable to real financial markets, as they do not take into account factors such as market volatility, economic cycles, etc. Consequently, the findings and applicability of this research article are questioned.</p></blockquote><blockquote><p>This research article does not provide sufficient evidence of the results obtained, nor does it demonstrate the applicability of the proposed model in practice. Markowitz&rsquo;s theory of portfolio selection is not applicable to all investors, as it does not consider the complications that can arise in practice, such as taxes or fees. Also, the use of the D-Wave quantum optimizer has not been adequately demonstrated. The relaxed wording does not involve buying shares, which means that the optimal outcome is not realistic. Also, the abundance of zeros in the data is unrealistic. Most of the sample code and applications mentioned in the article are computation related</p></blockquote><h2 id=conclusions>Conclusions<a hidden class=anchor aria-hidden=true href=#conclusions>#</a></h2><p>As I said earlier, I can&rsquo;t claim any strong subject mastership for evaluate if the outcome i got from the LLM have solid foundations or not, but at first sight they seem to be realistic and strong enough to suggest some thoughts.</p><p>For example, if we take the comment about the investment of only $100, this is actually a simplified scenario they considered in the paper, but to be honest I have no idea if this factor can effectively question the results.</p><p>In general, the thing that amazed me is the ease with which the framework makes the building blocks available for developing AI applications, without reinventing the wheel and integrating very well with the main providers and market products.</p><p>I realize the example shown is really trivial, but it opens up a world of possibilities. I&rsquo;m doing other tests by expanding the dataset and trying to answer slightly more complex questions. Stay tuned</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://c-daniele.github.io/en/tags/ai/>ai</a></li><li><a href=https://c-daniele.github.io/en/tags/langchain/>langchain</a></li></ul><nav class=paginav><a class=prev href=https://c-daniele.github.io/en/posts/2023-08-13-langchain-agents/><span class=title>« Prev</span><br><span>Langchain pt. 2 - Data Analysis through Agents</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share LLM - Experimenting LangChain - Part 1 on twitter" href="https://twitter.com/intent/tweet/?text=LLM%20-%20Experimenting%20LangChain%20-%20Part%201&amp;url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f&amp;hashtags=ai%2clangchain"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share LLM - Experimenting LangChain - Part 1 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f&amp;title=LLM%20-%20Experimenting%20LangChain%20-%20Part%201&amp;summary=LLM%20-%20Experimenting%20LangChain%20-%20Part%201&amp;source=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share LLM - Experimenting LangChain - Part 1 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f&title=LLM%20-%20Experimenting%20LangChain%20-%20Part%201"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share LLM - Experimenting LangChain - Part 1 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share LLM - Experimenting LangChain - Part 1 on whatsapp" href="https://api.whatsapp.com/send?text=LLM%20-%20Experimenting%20LangChain%20-%20Part%201%20-%20https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share LLM - Experimenting LangChain - Part 1 on telegram" href="https://telegram.me/share/url?text=LLM%20-%20Experimenting%20LangChain%20-%20Part%201&amp;url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share LLM - Experimenting LangChain - Part 1 on ycombinator" href="https://news.ycombinator.com/submitlink?t=LLM%20-%20Experimenting%20LangChain%20-%20Part%201&u=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://c-daniele.github.io/en/>Cdani's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>