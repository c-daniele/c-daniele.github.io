<!doctype html><html lang=en-US><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>LLM - Experimenting LangChain - Part 1 - Cdani's Blog</title><meta name=Description content="Cdani's Blog"><meta property="og:url" content="https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/"><meta property="og:site_name" content="Cdani's Blog"><meta property="og:title" content="LLM - Experimenting LangChain - Part 1"><meta property="og:description" content="Intro For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.
As the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:
Prompt Templates: they refer to a reproducible way to generate a prompt. Contains a text string (“the model”), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model The language model (LLM): LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc) Output Parsers: allow to extract structure data form from the answers returned by the linguistic model The framework has 2 very interesting features:"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-24T17:14:03+02:00"><meta property="article:modified_time" content="2023-07-24T17:45:02+02:00"><meta property="article:tag" content="GenAI"><meta property="article:tag" content="Langchain"><meta property="og:image" content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="LLM - Experimenting LangChain - Part 1"><meta name=twitter:description content="Intro For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.
As the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:
Prompt Templates: they refer to a reproducible way to generate a prompt. Contains a text string (“the model”), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model The language model (LLM): LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc) Output Parsers: allow to extract structure data form from the answers returned by the linguistic model The framework has 2 very interesting features:"><meta name=application-name content="Cdani's Blog"><meta name=apple-mobile-web-app-title content="Cdani's Blog"><meta name=referrer content="no-referrer"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/logo_cd_v3.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#00872b><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/><link rel=next href=https://c-daniele.github.io/en/posts/2023-08-13-langchain-agents/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"LLM - Experimenting LangChain - Part 1","inLanguage":"en-US","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/c-daniele.github.io\/en\/posts\/2023-07-24-langchain-helloworld-pdf\/"},"genre":"posts","keywords":"GenAI, Langchain","wordcount":1281,"url":"https:\/\/c-daniele.github.io\/en\/posts\/2023-07-24-langchain-helloworld-pdf\/","datePublished":"2023-07-24T17:14:03+02:00","dateModified":"2023-07-24T17:45:02+02:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Me"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script>const query=window.matchMedia("(prefers-color-scheme: dark)");function applyTheme(){let e=window.localStorage?.getItem("theme")||"auto",t=e==="dark"||e==="auto"&&query.matches;document.body.setAttribute("theme",t?"dark":"light"),document.body.setAttribute("cfg-theme",e)}applyTheme(),query.addEventListener("change",applyTheme)</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/en/ title="Cdani's Blog"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo_cd_v3.svg data-srcset="/logo_cd_v3.svg, /logo_cd_v3.svg 1.5x, /logo_cd_v3.svg 2x" data-sizes=auto alt=/logo_cd_v3.svg title=/logo_cd_v3.svg>Cdani's Blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/en/posts/>Archive </a><a class=menu-item href=/en/tags/>Tags </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=Search... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="menu-item language" title="Select Language"><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select id=language-select-desktop onchange="location=this.value"><option value=/it/posts/2023-07-24-langchain-helloworld-pdf/>Italiano</option><option value=/en/posts/2023-07-24-langchain-helloworld-pdf/ selected>English</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/en/ title="Cdani's Blog"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo_cd_v3.svg data-srcset="/logo_cd_v3.svg, /logo_cd_v3.svg 1.5x, /logo_cd_v3.svg 2x" data-sizes=auto alt=/logo_cd_v3.svg title=/logo_cd_v3.svg>Cdani's Blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=Search... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/en/posts/ title>Archive</a><a class=menu-item href=/en/tags/ title>Tags</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class=menu-item title="Select Language"><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select onchange="location=this.value"><option value=/it/posts/2023-07-24-langchain-helloworld-pdf/>Italiano</option><option value=/en/posts/2023-07-24-langchain-helloworld-pdf/ selected>English</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">LLM - Experimenting LangChain - Part 1</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/en/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Me</a></span>&nbsp;<span class=post-category>included in <a href=/en/categories/software-development/><i class="far fa-folder fa-fw" aria-hidden=true></i>Software Development</a>&nbsp;<a href=/en/categories/artificial-intelligence/><i class="far fa-folder fa-fw" aria-hidden=true></i>Artificial Intelligence</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime="July 24, 2023">July 24, 2023</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;1281 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;7 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#integration-with-unstructured-data>Integration with unstructured data</a></li><li><a href=#chains>Chains</a></li><li><a href=#the-experiment>The experiment</a><ul><li><a href=#the-code>The code</a></li><li><a href=#outcomes>Outcomes</a></li></ul></li><li><a href=#conclusions>Conclusions</a></li></ul></nav></div></div><div class=content id=content><h2 id=intro>Intro</h2><p>For those unfamiliar with it, LangChain is a framework for developing applications that make use of LLMs.</p><p>As the name suggests, LangChain is based on the concept of LLM Chain, which combines 3 elements:</p><ul><li><strong>Prompt Templates</strong>: they refer to a reproducible way to generate a prompt. Contains a text string (&ldquo;the model&rdquo;), which can accept a series of parameters from the end user and generates the definitive prompt which is passed as input to the model</li><li>The <strong>language model (LLM)</strong>: LangChain integrates with the most important providers (OpenAI, Cohere, Hugging Face, etc)</li><li><strong>Output Parsers</strong>: allow to extract structure data form from the answers returned by the linguistic model</li></ul><hr><p>The framework has 2 very interesting features:</p><ol><li>it can extend LLM knowledge with <strong>your own database</strong>, leveragine structured and unstructured datasets</li><li>it provides the &ldquo;<strong>Agent</strong>&rdquo; capabilities by which the action itself is an output returned from the LLM</li></ol><p>I was quite curious about the first item, so I&rsquo;ve started making some tests. I don&rsquo;t want to make a critical analysis of the model performance, but rather verify how easy is to integrate the framework into one&rsquo;s own database.</p><h2 id=integration-with-unstructured-data>Integration with unstructured data</h2><p>I didn&rsquo;t know where to start, so I took a look at the most documented use cases on the internet. I&rsquo;ve found a lot of documentation related to parsing PDF files, so it seemed like an area I could experiment with a lot.</p><p>In the official documentation there&rsquo;s a special section related to the &ldquo;<em>Data Connection</em>&rdquo;, which I found incredibly clear and intuitive. I will try to summarize here the most important points.</p><p>The building blocks made available by LangChain are the following:</p><ul><li><strong>Document</strong>: it&rsquo;s an abstraction containing both the data in textual form and the associated metadata</li><li><strong>Document loaders</strong>: They are classes that allow you to extract text and metadata from a specific type of data in order to build the &ldquo;Document&rdquo;</li><li><strong>Document transformers</strong>: it&rsquo;s used to process Documents. Since LLMs usually have strong limitations in terms of available tokens, the most common transformation is related to chunk splitting, through which it is possible to submit calls to the LLM provider in series or in parallel. There are also other types of transformers, for example: redundancy reduction, translation, metadata extraction, etc&mldr;</li><li><strong>Text embedding</strong>: it&rsquo;s the operation of translating a portion of text into an N-dimensional vector model, which is the core component for the semantic search operations based on similarity indexes and implemented by calculating vector distances across such N-dimensional space</li><li><strong>Vector stores</strong>: it stores the embeddings inside a vector DB Engine, which is capable of efficiently returning the vectors closest to the input text (and therefore the portions of text that are most similar). It&rsquo;s possible to exploit some open source DB engines to run everything locally, or to integrate with some market products that obviously offer much better performance (eg: Pinecone)</li><li><strong>Retrievers</strong>: it&rsquo;s an interface that returns documents from an unstructured query. It is a slightly more general concept than a Vector Store, but unlike the latter, it only allows you to return documents and not necessarily store them</li></ul><h2 id=chains>Chains</h2><p>So let&rsquo;s talk about the main components: the <strong>chains</strong>.</p><p>LangChain introduces this concept which represents a useful abstraction to implement applications that make use of LLMs in a simple and modular way.
There are many predefined Chains, the most common are:</p><ul><li><strong>RetrievalQA</strong>: it responds to user input from the output returned by a retriever</li><li><strong>ConversationalRetrievalChain</strong>: it&rsquo;s similar to RetrievalQA. It adds the capability to build a conversational experience through the history of exchanged messages</li><li><strong>Summarize</strong>: as the name suggests, it enable text summarization</li></ul><h2 id=the-experiment>The experiment</h2><p>I took a 2017 research paper, written by some researchers at the Oak Ridge National Laboratory (ORNL) and other university institutes, which proposes an implementation of a quantum computing algorithm for a Portfolio Optimization problem.</p><p>In particular, the article describes the advantages deriving from the use of a variant of the Markowitz model (QUBO) on D-Wave type quantum devices.</p><p>The complete article can be found at <a href=https://ieee-hpec.org/2017/techprog2017/index_htm_files/102.pdf target=_blank rel="noopener noreffer">this link</a>.</p><p>Being passionate about these topics, but not having a solid theoretical basis, I can understand the main points of the paper, but I have no competence to evaluate the reliability or the goodness of the results, so I decide to ask OpenAI for a critical analysis, passing through LangChain.</p><p>Surprisingly, it only took me a few hours and <strong>less than 20 lines of code</strong> to get a working prototype with an overall good result.</p><h3 id=the-code>The code</h3><p>Here you can find the source code. It&rsquo;s almost self-describing, but I&rsquo;m adding some further notes and comments below.</p><div class="code-block code-line-numbers open" style="counter-reset:code-block 0"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.llms</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.document_loaders</span> <span class=kn>import</span> <span class=n>PyPDFLoader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains.summarize</span> <span class=kn>import</span> <span class=n>load_summarize_chain</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain</span> <span class=kn>import</span> <span class=n>OpenAI</span><span class=p>,</span> <span class=n>PromptTemplate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>loader</span> <span class=o>=</span> <span class=n>PyPDFLoader</span><span class=p>(</span><span class=s2>&#34;docs/pdf/102.pdf&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>docs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>docs</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>loader</span><span class=o>.</span><span class=n>load</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt_template</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;Write a negative critique of this research article, questioning its findings and applicability:
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=si>{text}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>CRITICS:&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=n>PROMPT</span> <span class=o>=</span> <span class=n>PromptTemplate</span><span class=p>(</span><span class=n>template</span><span class=o>=</span><span class=n>prompt_template</span><span class=p>,</span> <span class=n>input_variables</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;text&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>chain</span> <span class=o>=</span> <span class=n>load_summarize_chain</span><span class=p>(</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span> <span class=n>chain_type</span><span class=o>=</span><span class=s2>&#34;map_reduce&#34;</span><span class=p>,</span> <span class=n>return_intermediate_steps</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>map_prompt</span><span class=o>=</span><span class=n>PROMPT</span><span class=p>,</span> <span class=n>combine_prompt</span><span class=o>=</span><span class=n>PROMPT</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>chain</span><span class=p>({</span><span class=s2>&#34;input_documents&#34;</span><span class=p>:</span> <span class=n>docs</span><span class=p>},</span> <span class=n>return_only_outputs</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></span></span></code></pre></div></div><p>The call to <code>load_dotenv()</code> is for loading the <em>OPENAI_API_KEY</em> environment variable, associated with my OpenAI account.
The first instructions are used to initialize the loader and create the associated &ldquo;Documents&rdquo;. Right after that, I define the prompt template and call the &ldquo;Summarize&rdquo; chain.
The first parameter passed to the Chain is an OpenAI-type LLM instantiation, which I deliberately configured with a temperature of 0.5, to push the creativity a little bit. The chain_type is &ldquo;<em>map_reduce</em>&rdquo; because the text is long enough to exceed the 4096 token limit imposed by the provider I&rsquo;m using (ChatGPT 3.5).</p><h3 id=outcomes>Outcomes</h3><p>Please find below a couple of outcomes I got from the above code:</p><blockquote><p>This research article presents a variety of methodologies for analyzing portfolio selection in the presence of multiple criteria. However, the results are based on mathematical theories and simulation models rather than real data. Also, using a fixed $100 budget is unrealistic and does not represent real-world conditions. Furthermore, most of the techniques described in this article are not applicable to real financial markets, as they do not take into account factors such as market volatility, economic cycles, etc. Consequently, the findings and applicability of this research article are questioned.</p></blockquote><blockquote><p>This research article does not provide sufficient evidence of the results obtained, nor does it demonstrate the applicability of the proposed model in practice. Markowitz&rsquo;s theory of portfolio selection is not applicable to all investors, as it does not consider the complications that can arise in practice, such as taxes or fees. Also, the use of the D-Wave quantum optimizer has not been adequately demonstrated. The relaxed wording does not involve buying shares, which means that the optimal outcome is not realistic. Also, the abundance of zeros in the data is unrealistic. Most of the sample code and applications mentioned in the article are computation related</p></blockquote><h2 id=conclusions>Conclusions</h2><p>As I said earlier, I can&rsquo;t claim any strong subject mastership for evaluate if the outcome i got from the LLM have solid foundations or not, but at first sight they seem to be realistic and strong enough to suggest some thoughts.</p><p>For example, if we take the comment about the investment of only $100, this is actually a simplified scenario they considered in the paper, but to be honest I have no idea if this factor can effectively question the results.</p><p>In general, the thing that amazed me is the ease with which the framework makes the building blocks available for developing AI applications, without reinventing the wheel and integrating very well with the main providers and market products.</p><p>I realize the example shown is really trivial, but it opens up a world of possibilities. I&rsquo;m doing other tests by expanding the dataset and trying to answer slightly more complex questions. Stay tuned</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on July 24, 2023</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on X" data-sharer=x data-url=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/ data-title="LLM - Experimenting LangChain - Part 1" data-hashtags=GenAI,Langchain><i class="fab fa-x-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Threads" data-sharer=threads data-url=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/ data-title="LLM - Experimenting LangChain - Part 1"><i class="fab fa-threads fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/ data-hashtag=GenAI><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/ data-title="LLM - Experimenting LangChain - Part 1"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/ data-title="LLM - Experimenting LangChain - Part 1"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@15.14.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/ data-title="LLM - Experimenting LangChain - Part 1"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Diaspora" data-sharer=diaspora data-url=https://c-daniele.github.io/en/posts/2023-07-24-langchain-helloworld-pdf/ data-title="LLM - Experimenting LangChain - Part 1" data-description><i class="fab fa-diaspora fa-fw" aria-hidden=true></i></a><a href="https://t.me/share/url?url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2023-07-24-langchain-helloworld-pdf%2f&amp;text=LLM%20-%20Experimenting%20LangChain%20-%20Part%201" target=_blank title="Share on Telegram"><i class="fab fa-telegram fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/en/tags/genai/>GenAI</a>,&nbsp;<a href=/en/tags/langchain/>Langchain</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/en/>Home</a></span></section></div><div class=post-nav><a href=/en/posts/2023-08-13-langchain-agents/ class=next rel=next title="Langchain pt. 2 - Data Analysis through Agents">Langchain pt. 2 - Data Analysis through Agents<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i></a></div><div id=fixed-buttons-hidden><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js></script><script>window.config={comment:{},search:{highlightTag:"em",lunrIndexURL:"/en/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script src=/js/theme.min.js></script><script>var dnt,doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8NZQZ3Z1RN")}</script><script src="https://www.googletagmanager.com/gtag/js?id=G-8NZQZ3Z1RN" async></script></body></html>