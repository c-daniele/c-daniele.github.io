<!doctype html><html lang=en-US><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Langchain pt. 3 - How to call Rest API in natural language - Cdani's Blog</title><meta name=Description content="Cdani's Blog"><meta property="og:url" content="https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/"><meta property="og:site_name" content="Cdani's Blog"><meta property="og:title" content="Langchain pt. 3 - How to call Rest API in natural language"><meta property="og:description" content="Intro Last year, Gartner put Generative AI at the peak of inflated expectations in its AI Hype Cycle.
Recently, big tech leaders compared the hype around GenAI to the dotcom bubble. Furthermore, according to some rumors, the main Cloud Providers are even giving instructions to their Sales Teams to slow down the enthusiasm towards customers regarding GenAI initiatives and promoting cost-vs-benefits awareness. Has the drop into the trough of disillusionment already begun?"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-04-20T19:00:00+02:00"><meta property="article:modified_time" content="2024-04-20T19:00:00+02:00"><meta property="article:tag" content="GenAI"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Api"><meta property="article:tag" content="Swagger"><meta property="article:tag" content="OpenAPI"><meta property="og:image" content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://c-daniele.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Langchain pt. 3 - How to call Rest API in natural language"><meta name=twitter:description content="Intro Last year, Gartner put Generative AI at the peak of inflated expectations in its AI Hype Cycle.
Recently, big tech leaders compared the hype around GenAI to the dotcom bubble. Furthermore, according to some rumors, the main Cloud Providers are even giving instructions to their Sales Teams to slow down the enthusiasm towards customers regarding GenAI initiatives and promoting cost-vs-benefits awareness. Has the drop into the trough of disillusionment already begun?"><meta name=application-name content="Cdani's Blog"><meta name=apple-mobile-web-app-title content="Cdani's Blog"><meta name=referrer content="no-referrer"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/logo_cd_v3.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#00872b><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/><link rel=prev href=https://c-daniele.github.io/en/posts/2023-08-13-langchain-agents/><link rel=next href=https://c-daniele.github.io/en/posts/2025-05-15-policy-puppetry/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Langchain pt. 3 - How to call Rest API in natural language","inLanguage":"en-US","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/c-daniele.github.io\/en\/posts\/2024-04-20-langchain-api\/"},"genre":"posts","keywords":"GenAI, Langchain, Api, Swagger, OpenAPI","wordcount":2044,"url":"https:\/\/c-daniele.github.io\/en\/posts\/2024-04-20-langchain-api\/","datePublished":"2024-04-20T19:00:00+02:00","dateModified":"2024-04-20T19:00:00+02:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Me"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script>const query=window.matchMedia("(prefers-color-scheme: dark)");function applyTheme(){let e=window.localStorage?.getItem("theme")||"auto",t=e==="dark"||e==="auto"&&query.matches;document.body.setAttribute("theme",t?"dark":"light"),document.body.setAttribute("cfg-theme",e)}applyTheme(),query.addEventListener("change",applyTheme)</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/en/ title="Cdani's Blog"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo_cd_v3.svg data-srcset="/logo_cd_v3.svg, /logo_cd_v3.svg 1.5x, /logo_cd_v3.svg 2x" data-sizes=auto alt=/logo_cd_v3.svg title=/logo_cd_v3.svg>Cdani's Blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/en/posts/>Archive </a><a class=menu-item href=/en/tags/>Tags </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=Search... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="menu-item language" title="Select Language"><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select id=language-select-desktop onchange="location=this.value"><option value=/it/posts/2024-04-20-langchain-api/>Italiano</option><option value=/en/posts/2024-04-20-langchain-api/ selected>English</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/en/ title="Cdani's Blog"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo_cd_v3.svg data-srcset="/logo_cd_v3.svg, /logo_cd_v3.svg 1.5x, /logo_cd_v3.svg 2x" data-sizes=auto alt=/logo_cd_v3.svg title=/logo_cd_v3.svg>Cdani's Blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=Search... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/en/posts/ title>Archive</a><a class=menu-item href=/en/tags/ title>Tags</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class=menu-item title="Select Language"><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select onchange="location=this.value"><option value=/it/posts/2024-04-20-langchain-api/>Italiano</option><option value=/en/posts/2024-04-20-langchain-api/ selected>English</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Langchain pt. 3 - How to call Rest API in natural language</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/en/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Me</a></span>&nbsp;<span class=post-category>included in <a href=/en/categories/software-development/><i class="far fa-folder fa-fw" aria-hidden=true></i>Software Development</a>&nbsp;<a href=/en/categories/artificial-intelligence/><i class="far fa-folder fa-fw" aria-hidden=true></i>Artificial Intelligence</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime="April 20, 2024">April 20, 2024</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;2044 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;10 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#technical-preamble>Technical preamble</a></li><li><a href=#the-apis>The APIs</a></li><li><a href=#apichain>APIChain</a></li><li><a href=#the-test>The test</a></li><li><a href=#behind-the-scenes>Behind the scenes</a></li><li><a href=#final-thoughts>Final thoughts</a></li></ul></nav></div></div><div class=content id=content><h2 id=intro>Intro</h2><p>Last year, Gartner put Generative AI at the peak of inflated expectations in its AI <a href=https://www.gartner.com/en/articles/what-s-new-in-artificial-intelligence-from-the-2023-gartner-hype-cycle target=_blank rel="noopener noreffer">Hype Cycle</a>.</p><p>Recently, big tech leaders <a href=https://www.wired.com/story/amazons-cloud-boss-selipsky-generative-ai-hype/ target=_blank rel="noopener noreffer">compared the hype around GenAI to the <em>dotcom</em> bubble</a>.
Furthermore, according to some <a href="https://www.theinformation.com/articles/generative-ai-providers-quietly-tamp-down-expectations?ref=wheresyoured.at" target=_blank rel="noopener noreffer">rumors</a>, the main Cloud Providers are even giving instructions to their Sales Teams to slow down the enthusiasm towards customers regarding GenAI initiatives and promoting cost-vs-benefits awareness.
Has the drop into the <a href=https://it.wikipedia.org/wiki/Hype_cycle target=_blank rel="noopener noreffer">trough of disillusionment</a> already begun?</p><p><figure><a href=/images/20240420/Hype-Cycle-General.png><img src=/images/20240420/Hype-Cycle-General.png alt="Figure 1 - Hype Cycle Model"></a><figcaption>Figure 1 - Hype Cycle Model</figcaption></figure></p><p>Maybe the classic Hype Cycle model is not applicable this time.
Compared to other transformative and technological trends, we are moving very quickly towards a phase of awareness and maturity.
The market is moving beyond the race for the most powerful model in terms of &ldquo;brute force&rdquo; and new market trends arise:</p><ul><li>Many vendors are working on relatively small models that can also be run locally, for example:<ul><li>Meta and Qualcomm have recently <a href=https://www.qualcomm.com/news/releases/2024/04/qualcomm-enables-meta-llama-3-to-run-on-devices-powered-by-snapd target=_blank rel="noopener noreffer">accounced a collaboration</a> aimed to optimize the <em>Llama3</em> models in order to make them executed directly on devices equipped with future top-of-the-range Snapdragon platforms</li><li>H2O launched a super tiny language model called <a href=https://venturebeat.com/ai/h2o-ai-releases-danube-a-super-tiny-llm-for-mobile-applications/ target=_blank rel="noopener noreffer"><em>Danube</em></a>, which is a fork from <em>Llama2</em> designed to be to be executed on mobile devices</li><li><a href=https://www.bloomberg.com/news/newsletters/2024-04-21/apple-aapl-growth-opportunities-southeast-asia-and-africa-lower-end-iphone-lv9itkna target=_blank rel="noopener noreffer">Rumors on Apple</a> reported that they are working on a &ldquo;<em>on-device</em>&rdquo; language model which will also be available offline</li></ul></li><li>All the big players in the AI market are introducing multi-modal products</li><li>Several frameworks are emerging for designing modular solutions, using LLM models as building blocks to build complex and vendor-agnostic <em>&ldquo;AI-powered&rdquo;</em> applications<ul><li>In other words, to draw a parallel with what happened many years ago with the birth of software engineering, these products are paving the way for <strong>&ldquo;AI Engineering&rdquo;</strong></li></ul></li></ul><p>LangChain is going precisely in this direction.
It&rsquo;s one of the most complete and powerful AI Open Source frameworks at the moment. It provides great control and flexibility for various use cases and offers greater granularity than other frameworks such as, for example, <em>LlamaIndex</em>.
One of the features I have tested in recent days is the Rest-API integration, using well-defined standard specifications (e.g. <em>Swagger</em>, <em>OpenApi</em>) or even described in natural language.</p><p>In this article, I will show how to integrate a third-party API &ldquo;at runtime&rdquo; into a very simple chatbot, and query the API in natural language <strong>without any prior knowledge</strong> about the API specifications.</p><h2 id=technical-preamble>Technical preamble</h2><p>The code shown below, <a href=https://github.com/c-daniele/langchain_tests/tree/main/01.APIChain target=_blank rel="noopener noreffer">available on GitHub</a> is making use of <em>OpenAI</em> and <em>Bedrock</em>. The latter, for those who don&rsquo;t know it, is the AWS service that gives access to various models including <em>Llama2</em>, <em>Claude</em>, <em>Mistral</em> and the AWS proprietary model called <em>Titan</em>.
The code is extremely simple and can be summarized as the following logical steps:</p><ol><li>Environment variable settings</li><li>LLM initialization</li><li>API specifications dynamic retrieval</li><li>Setup and invoke of the <em>APIChain</em> component. This component applies some simple Prompt Engineering techniques to perform the following 3 actions:<ol><li>Take the user&rsquo;s question in natural language as input and construct, via the LLM, the URL to be invoked</li><li>Invoke the URL thus built via an HTTP call</li><li>Wrap the response obtained from the HTTP call into a new LLM invocation and obtain the information requested by the user in terms of natural language.</li></ol></li></ol><p>The overall process is summarized into the following flow diagram:</p><p><figure><a href=/images/20240420/FlowChart-APIChain-v2.png><img src=/images/20240420/FlowChart-APIChain-v2.png alt="Figure 2 - Flow Diagram"></a><figcaption>Figure 2 - Flow Diagram</figcaption></figure></p><p>For sake of simplicity, in the code that follows I have hard-coded the user interactions parts, but it&rsquo;s easy to obtain these inputs dynamically via a dialogic user interation in a Chatbot application.
In such a scenario, you could also configure the APIs specifications using a well-defined administration interface and then plug&amp;play directly the API into the chatbot to <strong>add features at-runtime</strong>.</p><p>In other words, with very small effort, you can build a <strong>chatbot that is completely agnostic</strong> with respect to the API specifications and dynamically adapts to the user needs, adding references to new APIs on the fly.</p><p>As real use case, you can imagine a <strong>customer care</strong> tool that integrates with company APIs to directly return information related to the customer orders, products, reports, etc.. You can thus develop these features incrementally, while enhancing the capabilities exposed by the chatbot and use a <strong>plug&amp;play</strong> approach, adding new APIs within the existing dialogic process.</p><p>Broadening the discussion and moving towards a more Enterprise context, we can imagine the scenario of a modern Data Platform that makes the company KPIs available in the form of <em>Data-APIs</em> thus allowing anyone in the company accessing such KPIs via the enterprise chatbot.</p><h2 id=the-apis>The APIs</h2><p>The APIs I&rsquo;ve used to test are the following:</p><ul><li><em><a href=https://www.klarna.com/us/shopping/public/openai/v0/api-docs/ target=_blank rel="noopener noreffer">klarna.com</a></em><ul><li>for those who don&rsquo;t know the brand, Klarna is a Swedish fintech that offers payment processing services for the e-commerce industry. Klarma payment options are usually available on most common online shopping websites. The Klarna API can be accessed for free and allows searching for products based on text description, price, brand, etc.. It is only available in a few countries (US, GB, DE, SE, DK).</li></ul></li><li><em><a href=https://raw.githubusercontent.com/open-meteo/open-meteo/main/openapi.yml target=_blank rel="noopener noreffer">open-meteo</a></em><ul><li>It&rsquo;s a free API that makes meteorological data available. The most common use case is when we query the API to obtain the weather conditions in a certain city, in terms of temperature, precipitation, visibility, etc.</li></ul></li></ul><h2 id=apichain>APIChain</h2><p>The main component we are going to use within the LangChain suite is called <em>APIChain</em>. Under the hood, the chain is made of:</p><ul><li>An instance of an <em>LLMChain</em>, which is used to build the URL and the HTTP parameters from the natural language question</li><li>A wrapper of the <em>request</em> component, which is used to send the HTTP request</li><li>An instance of an <em>LLMChain</em> that is used to build the response in natural language, starting from the raw HTTP Response payload</li><li>Some pre-built prompts that are used to prepare the context and effectively implement invocations of the LLM</li></ul><p>As regards the prompts that the APIChain component makes available, during the tests I realized that they did not work correctly with all LLMs (for example: they worked with OpenAI, but not with Llama2, Claude, etc). Therefore, I&rsquo;ve built a slightly better version of such prompts and proposed the change on the official repo (we&rsquo;ll see if they accept it &#x1f603; ).</p><h2 id=the-test>The test</h2><p>You can find the full <a href=https://github.com/c-daniele/langchain_tests/tree/main/01.APIChain target=_blank rel="noopener noreffer">source code in the GitHub</a> repository.</p><p>In the first part of the code I&rsquo;ve initialized the basic components and created the models.</p><p>Some notes:</p><ul><li>The environment variables related to integration with OPEN_AI and AWS must be configured in the <em>.env</em> file</li><li>I&rsquo;ve created a wrapper for instantiating the LLM model (see the <em>&ldquo;libs.py&rdquo;</em> file)</li><li>Some of the involved AWS services are currently only available in some Regions. Therefore you need to pay attention to the region settings and the costs associated with use</li></ul><div class="code-block open" style="counter-reset:code-block 0"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains</span> <span class=kn>import</span> <span class=n>APIChain</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>httpx</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>logging</span> <span class=k>as</span> <span class=nn>logger</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># see &#34;libs.py&#34; file</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>libs</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># see &#34;prompt_improved.py&#34; file</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_improved</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Set WARNING Logger levels help print only meaningful text</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>stream</span><span class=o>=</span><span class=n>sys</span><span class=o>.</span><span class=n>stdout</span><span class=p>,</span> <span class=n>level</span><span class=o>=</span><span class=n>logger</span><span class=o>.</span><span class=n>WARNING</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=s1>&#39;botocore&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>setLevel</span><span class=p>(</span><span class=n>logger</span><span class=o>.</span><span class=n>WARNING</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=s1>&#39;httpx&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>setLevel</span><span class=p>(</span><span class=n>logger</span><span class=o>.</span><span class=n>WARNING</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># loading ENV variables</span>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize Models</span>
</span></span><span class=line><span class=cl><span class=n>gpt35</span> <span class=o>=</span> <span class=n>create_llm</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;provider&#34;</span><span class=p>:</span><span class=s2>&#34;OpenAI&#34;</span><span class=p>,</span> <span class=s2>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;gpt-3.5-turbo&#34;</span><span class=p>},</span> <span class=n>model_kwargs</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;temperature&#34;</span><span class=p>:</span> <span class=mf>0.1</span><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=n>gpt4</span> <span class=o>=</span> <span class=n>create_llm</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;provider&#34;</span><span class=p>:</span><span class=s2>&#34;OpenAI&#34;</span><span class=p>,</span> <span class=s2>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;gpt-4&#34;</span><span class=p>},</span> <span class=n>model_kwargs</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;temperature&#34;</span><span class=p>:</span> <span class=mf>0.1</span><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=n>claude3</span> <span class=o>=</span> <span class=n>create_llm</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;provider&#34;</span><span class=p>:</span><span class=s2>&#34;Anthropic&#34;</span><span class=p>,</span> <span class=s2>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;anthropic.claude-3-sonnet-20240229-v1:0&#34;</span><span class=p>},</span> <span class=n>model_kwargs</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;temperature&#34;</span><span class=p>:</span> <span class=mf>0.1</span><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=n>llama2</span> <span class=o>=</span> <span class=n>create_llm</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;provider&#34;</span><span class=p>:</span><span class=s2>&#34;Meta&#34;</span><span class=p>,</span> <span class=s2>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;meta.llama2-70b-chat-v1&#34;</span><span class=p>},</span> <span class=n>model_kwargs</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></span></span></code></pre></div></div><p>Ok, now let&rsquo;s see how to dynamically integrate the interface descriptor and pass it to the APIChain component.
The <em>&ldquo;limit_to_domains&rdquo;</em> variable is used to introduce a security mechanism that limits the domains to which requests can be directed. You could also set it to &ldquo;None&rdquo; to remove such constraints (not recommended).
The variables <em>api_url_prompt</em> and <em>api_response_prompt</em> allow you to customize the prompts to be passed to the LLM. As I mentioned previously, I&rsquo;ve set up 2 custom prompts that proved to be more robust than the default ones.</p><div class="code-block open" style="counter-reset:code-block -1"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Dynamically retrieve swagger</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>httpx</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;https://www.klarna.com/us/shopping/public/openai/v0/api-docs/&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>swagger</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># build the APIChain </span>
</span></span><span class=line><span class=cl><span class=n>chain</span> <span class=o>=</span> <span class=n>APIChain</span><span class=o>.</span><span class=n>from_llm_and_api_docs</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>llm</span><span class=o>=</span><span class=n>gpt4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>api_docs</span><span class=o>=</span><span class=n>swagger</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>limit_to_domains</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;klarna.com&#34;</span><span class=p>,</span> <span class=s2>&#34;https://www.klarna.com/&#34;</span><span class=p>,</span> <span class=s2>&#34;https://www.klarna.com&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>api_url_prompt</span><span class=o>=</span><span class=n>FINE_TUNED_API_URL_PROMPT</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>api_response_prompt</span><span class=o>=</span><span class=n>FINE_TUNED_API_RESPONSE_PROMPT</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div></div><p>At this point everything is set. We can ask a question and pass it to the framework and then return the output to the end user.
I&rsquo;ve asked to look for 3 t-shirts with a maximum price of 50 dollars and return price, description and the source link.</p><div class="code-block open" style="counter-reset:code-block -1"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Ask a question to the Chain</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Find 3 t-shirts, max 50 USD. For each Product print the Description, the Price and the corresponding URL&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the Chain Output</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s1>&#39;output&#39;</span><span class=p>])</span></span></span></code></pre></div></div><p>This is the output I got on the first try:</p><div class="code-block code-line-numbers open" style="counter-reset:code-block 0"><div class="code-header language-text"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>1. *Product: Polo Ralph Lauren Men&#39;s Slim Fit Wicking Crew Undershirts 3-pack - White*
</span></span><span class=line><span class=cl>   *Price: $37.99*
</span></span><span class=line><span class=cl>   *URL: https://www.klarna.com/us/shopping/pl/cl10001/3207134809/Clothing/Polo-Ralph-Lauren-Men-s-Slim-Fit-Wicking-Crew-Undershirts-3-pack-White/?utm_source=openai&amp;ref-site=openai_plugin*
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2. *Product: Lacoste Men&#39;s T-shirts 3-pack - Black*
</span></span><span class=line><span class=cl>   *Price: $31.90*
</span></span><span class=line><span class=cl>   *URL: https://www.klarna.com/us/shopping/pl/cl10001/3202043025/Clothing/Lacoste-Men-s-T-shirts-3-pack-Black/?utm_source=openai&amp;ref-site=openai_plugin*
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>3. *Product: SKIMS Cotton Jersey T-shirt*
</span></span><span class=line><span class=cl>   *Price: $48.00*
</span></span><span class=line><span class=cl>   *URL: https://www.klarna.com/us/shopping/pl/cl10001/3202929904/Clothing/SKIMS-Cotton-Jersey-T-shirt/?utm_source=openai&amp;ref-site=openai_plugin*</span></span></code></pre></div></div><p>Not bad!</p><p>I did several other tests with the other models and obtained similar performances although, as I expected, GPT4 and Claude3 are on average more precise.</p><p>As for the second API, the code is practically the same. You just have to modify the reference to the URL descriptor (swagger), the <em>limit_to_domains</em> variable which must be consistent with the API and the user&rsquo;s question.
So, I&rsquo;m omitting the first part of the Python script.</p><p><em>Warning</em>: There is no official swagger for this API, so I&rsquo;ve used the YAML file I&rsquo;ve found on GitHub. I have noticed that sometimes HTTP calls to GitHub fail. In that case I suggest to try again a couple of times.</p><div class="code-block open" style="counter-reset:code-block -1"><div class="code-header language-python"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Dynamically retrieve swagger</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>httpx</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;https://raw.githubusercontent.com/open-meteo/open-meteo/main/openapi.yml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>meteo_swagger</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># build the APIChain </span>
</span></span><span class=line><span class=cl><span class=n>chain</span> <span class=o>=</span> <span class=n>APIChain</span><span class=o>.</span><span class=n>from_llm_and_api_docs</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>llm</span><span class=o>=</span><span class=n>claude3</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>api_docs</span><span class=o>=</span><span class=n>meteo_swagger</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>limit_to_domains</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>api_url_prompt</span><span class=o>=</span><span class=n>FINE_TUNED_API_URL_PROMPT</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>api_response_prompt</span><span class=o>=</span><span class=n>FINE_TUNED_API_RESPONSE_PROMPT</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Ask a question to the Chain</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;What is the weather like right now in Munich, Germany in degrees Fahrenheit?&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the Chain Output</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s1>&#39;output&#39;</span><span class=p>])</span></span></span></code></pre></div></div><p>The output with Claude, GPT 3.5 and GPT4 is good as expected. The 2 Langchain calls have built the URL and processed the response, transforming it into natural language.</p><div class="code-block code-line-numbers open" style="counter-reset:code-block 0"><div class="code-header language-text"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>The current weather in Munich, Germany is 45.7°F with a wind speed of 17.7 km/h coming from 264° direction.</span></span></code></pre></div></div><p>The same test with Llama2 was unsuccessful as it hallucinated the first call, in which LangChain creates the URL, adding some unexpected parameters.</p><h2 id=behind-the-scenes>Behind the scenes</h2><p>Another super interesting tool from the LangChain suite is called <a href=https://www.langchain.com/langsmith target=_blank rel="noopener noreffer"><em>LangSmith</em></a>, which allows you to monitor and profile all model invocations.
In addition to this, it allows you to do many other things, such as:</p><ul><li>advanced debugging</li><li>continuous evaluation of the AI application through pre-defined datasets and evaluation criteria</li><li>tracing annotations, in order to collect user feedback within the application</li><li>many other features for monitoring and improving LangChain applications</li></ul><p>Using LangSmith, you can see the overall process and the underlying LLM invocations.</p><p><figure><a href=/images/20240420/langsmith_input_root_calls.png><img src=/images/20240420/langsmith_input_root_calls.png alt="Figure 3 - Underlying LangChain invocations"></a><figcaption>Figure 3 - Underlying LangChain invocations</figcaption></figure></p><p>In the image above you can clearly see the invocation tree, identified by the root <em>&ldquo;APIChain&rdquo;</em>, which is made of 2 LLM child chains, each one calling the OpenAI Chain.
You can also see useful information like the <em>number of used tokens</em> and the <em>estimated cost</em> for each LLM invocation.</p><p>If you click on the items, you can also see the actual prompt and the response for each LLM invocation.</p><p><figure><a href=/images/20240420/langsmith_input_00.png><img src=/images/20240420/langsmith_input_00.png alt="Figure 4 - URL building step"></a><figcaption>Figure 4 - URL building step</figcaption></figure></p><p><figure><a href=/images/20240420/langsmith_input_01.png><img src=/images/20240420/langsmith_input_01.png alt="Figure 5 - Final prompt and summary of the response in natural language"></a><figcaption>Figure 5 - Final prompt and summary of the response in natural language</figcaption></figure></p><h2 id=final-thoughts>Final thoughts</h2><p>If you take a look at the LangChain source code and LangSmith profiling tools you can clearly see there is no rocket science under the hood, cause it&rsquo;s mostly implemented through Prompt Engineering techniques. Nevertheless these tecniques allow extremely powerful integration between new AI applications and traditional systems.</p><p>In my opinion, it is one of the clearest examples of how today we can (and perhaps we should) <strong>review the human/machine interaction</strong> in terms of integration between well-specified formal systems with predictable behavior (e.g. any traditional software system in the company) and natural language.</p><p>LangChain and other frameworks allow you to do something similar even at a lower level, for example by querying a database in natural language and using an LLM to generate the underlying queries.
Even ignoring performance and scalability issues, this approach is good in theory but, based on my experience, there are several practical problems that make me think it is not really applicable but in some specific scenarios, since in most cases you&rsquo;ll find application layering and poor or missing data catalogs.
Conversely, enterprise APIs usually speak a Business-related language and have self-descriptive metadatas.</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on April 20, 2024</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on X" data-sharer=x data-url=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/ data-title="Langchain pt. 3 - How to call Rest API in natural language" data-hashtags=GenAI,Langchain,Api,Swagger,OpenAPI><i class="fab fa-x-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Threads" data-sharer=threads data-url=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/ data-title="Langchain pt. 3 - How to call Rest API in natural language"><i class="fab fa-threads fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/ data-hashtag=GenAI><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/ data-title="Langchain pt. 3 - How to call Rest API in natural language"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/ data-title="Langchain pt. 3 - How to call Rest API in natural language"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@15.14.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/ data-title="Langchain pt. 3 - How to call Rest API in natural language"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Diaspora" data-sharer=diaspora data-url=https://c-daniele.github.io/en/posts/2024-04-20-langchain-api/ data-title="Langchain pt. 3 - How to call Rest API in natural language" data-description><i class="fab fa-diaspora fa-fw" aria-hidden=true></i></a><a href="https://t.me/share/url?url=https%3a%2f%2fc-daniele.github.io%2fen%2fposts%2f2024-04-20-langchain-api%2f&amp;text=Langchain%20pt.%203%20-%20How%20to%20call%20Rest%20API%20in%20natural%20language" target=_blank title="Share on Telegram"><i class="fab fa-telegram fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/en/tags/genai/>GenAI</a>,&nbsp;<a href=/en/tags/langchain/>Langchain</a>,&nbsp;<a href=/en/tags/api/>Api</a>,&nbsp;<a href=/en/tags/swagger/>Swagger</a>,&nbsp;<a href=/en/tags/openapi/>OpenAPI</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/en/>Home</a></span></section></div><div class=post-nav><a href=/en/posts/2023-08-13-langchain-agents/ class=prev rel=prev title="Langchain pt. 2 - Data Analysis through Agents"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Langchain pt. 2 - Data Analysis through Agents</a>
<a href=/en/posts/2025-05-15-policy-puppetry/ class=next rel=next title="Policy Puppetry Prompt Injection">Policy Puppetry Prompt Injection<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i></a></div><div id=fixed-buttons-hidden><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js></script><script>window.config={comment:{},search:{highlightTag:"em",lunrIndexURL:"/en/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script src=/js/theme.min.js></script><script>var dnt,doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8NZQZ3Z1RN")}</script><script src="https://www.googletagmanager.com/gtag/js?id=G-8NZQZ3Z1RN" async></script></body></html>